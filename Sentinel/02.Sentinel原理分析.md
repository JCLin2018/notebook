# Sentinel原理分析

在Sentinel中，所有的资源都对应一个资源名称以及一个Entry。每一个entry可以表示一个请求。而 Sentinel中，会针对当前请求基于规则的判断来实现流控的控制，原理如下图所示。

![](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/Sentinel/20201208205139.jpg)

当一个外部请求过来之后，会创建一个Entry，而创建Entry的同时，也会创建一系列的slot 组成一个责 任链，每个slot有不同的工作职责。

- `NodeSelectorSlot` 负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级； 
- `ClusterBuilderSlot` 则用于存储资源的统计信息以及调用者信息，例如该资源的 RT, QPS, thread count 等等，这些信息将用作为多维度限流，降级的依据； 
- `StatisticSlot` 则用于记录、统计不同纬度的 runtime 指标监控信息； 
- `FlowSlot` 则用于根据预设的限流规则以及前面 slot 统计的状态，来进行流量控制； 
- `AuthoritySlot` 则根据配置的黑白名单和调用来源信息，来做黑白名单控制； 
- `DegradeSlot` 则通过统计信息以及预设的规则，来做熔断降级； 
- `SystemSlot` 则通过系统的状态，例如 load1 等，来控制总的入口流量； 
- `LogSlot` 在出现限流、熔断、系统保护时负责记录日志
- ...

Sentinel 将 `ProcessorSlot` 作为 SPI 接口进行扩展（1.7.2 版本以前 `SlotChainBuilder` 作为 SPI），使得 Slot Chain 具备了扩展的能力。您可以自行加入自定义的 slot 并编排 slot 间的顺序，从而 可以给 Sentinel 添加自定义的功能。

![](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/Sentinel/20201208205353.jpg)

## Spring Cloud 集成Sentinel的原理

Spring Cloud 中集成Sentinel限流，是基于过滤器来实现，具体的实现路径如下。

- SentinelWebAutoConfiguration 
  - addInterceptors 
    - SentinelWebInterceptor->AbstractSentinelInterceptor

```java
@Override
public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)
    throws Exception {
    try {
        String resourceName = getResourceName(request);

        if (StringUtil.isNotEmpty(resourceName)) {
            // Parse the request origin using registered origin parser.
            String origin = parseOrigin(request);
            ContextUtil.enter(SENTINEL_SPRING_WEB_CONTEXT_NAME, origin);
            Entry entry = SphU.entry(resourceName, ResourceTypeConstants.COMMON_WEB, EntryType.IN);

            setEntryInRequest(request, baseWebMvcConfig.getRequestAttributeName(), entry);
        }
        return true;
    } catch (BlockException e) {
        handleBlockException(request, response, e);
        return false;
    }
}
```

> 资源调用的流量类型，是入口流量（ EntryType.IN ）还是出口流量（ EntryType.OUT ），注意 系统规则只对 IN 生效

## Dubbo集成Sentinel的原理

在集成Dubb的案例中，引入了一个适配的包，这个包会提供集成Sentinel的功能。

```xml
<dependency>
    <groupId>com.alibaba.csp</groupId>
    <artifactId>sentinel-apache-dubbo-adapter</artifactId>
</dependency>
```

分别提供了两个类

- SentinelDubboConsumerFilter
- SentinelDubboProviderFilter

分别提供针对服务消费端的过滤器，和服务提供端的过滤器。

最终，当触发限流或者降级时，可以实现一个全局的DubboFallback回调，分别为服务提供端、服务消 费端提供fallback的实现。

然后需要调用 DubboFallbackRegistry 的 setConsumerFallback 和 setProviderFallback 方法分别注册 消费端，服务端相关的监听器。通常只需要在启动应用的时候，将其进行注册即可。

## SphU.entry

不管是集成dubbo也好，还是集成到spring cloud中也好，最终都是调用SphU.entry这个方法来进行限 流判断的，接下来我们从SphU.entry这个方法中去了解它的实现原理。

- ResourceWrapper 表示sentinel的资源，做了封装 
- count表示本次请求的占用的并发数量，默认是1 
- prioritized，优先级

**Resource**

资源，是Sentinel世界中的抽象，任何东西都能被定义成资源，自己提供的服务，调用的服务，甚至一段代码，有了资源才能在资源上定义规则，去进行限流降级之类的操作

在Sentinel中提供了两个默认是Resource分别是StringResourceWrapper和MethodResourceWrapper

**Entry**

每次调用 `SphU.entry()` 都会生成一个Entry入口，该入口中会保存了以下数据：入口的创建时间，当前入口所关联的节点(Node)，当前入口所关联的调用源对应的节点。Entry是一个抽象类，他只有一个实现类，在CtSph中的一个静态类：CtEntry

其中有这些属性

- createtime
- curNode
- originNode
- error
- resourceWrapper
- parent
- child
- chain
- context

一个Entry相当于一个token只有正常生成了一个entry才能算pass，不然报异常BlockException肯定是限流了

```java
public static Entry entry(String name, int resourceType, EntryType type) throws BlockException {
    return Env.sph.entryWithType(name, resourceType, type, 1, OBJECTS0);
}

private Entry entryWithPriority(ResourceWrapper resourceWrapper, int count, boolean prioritized, Object... args) throws BlockException {
    // 获取上下文环境，存储在ThreadLocal中，context中会存储整个调用链
    Context context = ContextUtil.getContext();
    if (context instanceof NullContext) { // 上下文context已经超过阈值，不进行规则检查，只初始化CtEntry
        // The {@link NullContext} indicates that the amount of context has exceeded the threshold,
        // so here init the entry only. No rule checking will be done.
        return new CtEntry(resourceWrapper, null, context);
    }

    if (context == null) { // 使用默认context
        // Using default context.
        context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME);
    }

    // Global switch is close, no rule checking will do.
    if (!Constants.ON) { // 全局限流开关是否已经开启，如果关闭了，就不进行限流规则检查
        return new CtEntry(resourceWrapper, null, context);
    }
	// 构建一个slot链表
    ProcessorSlot<Object> chain = lookProcessChain(resourceWrapper);

    /*
    * Means amount of resources (slot chain) exceeds {@link Constants.MAX_SLOT_CHAIN_SIZE},
    * so no rule checking will be done.
    */
    // 在生成chain的里面有个判断，如果chainMap.size大于一个值就返回null，也不进行规则检测
    if (chain == null) {
        return new CtEntry(resourceWrapper, null, context);
    }
	// 下面这里才真正开始，生成个entry
    Entry e = new CtEntry(resourceWrapper, chain, context);
    try {
        // 开始检测限流规则
        chain.entry(context, resourceWrapper, null, count, prioritized, args);
    } catch (BlockException e1) {
        e.exit(count, args); // 被限流，抛出异常
        throw e1;
    } catch (Throwable e1) {
        // This should not happen, unless there are errors existing in Sentinel internal.
        RecordLog.info("Sentinel unexpected exception", e1);
    }
    return e; // 返回正常的结果
}
```

### 1.ContextUtil.getContext  (一个线程对应一个Context)

```java
private static ThreadLocal<Context> contextHolder = new ThreadLocal<>();

public static Context getContext() {
    return contextHolder.get();
}
```

#### Context == null

```java
if (context == null) {
    // Using default context.
    context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME);
}
```

```java
protected static Context trueEnter(String name, String origin) {
    // 从ThreadLocal中获取，第一次肯定是null
    Context context = contextHolder.get();
    if (context == null) {
        // 这里是根据Context的名字获取Node
        Map<String, DefaultNode> localCacheNameMap = contextNameNodeMap;
        DefaultNode node = localCacheNameMap.get(name);
        if (node == null) {
            if (localCacheNameMap.size() > Constants.MAX_CONTEXT_NAME_SIZE) {
                setNullContext();
                return NULL_CONTEXT;
            } else {
                try {
                    LOCK.lock();
                    node = contextNameNodeMap.get(name);
                    if (node == null) {
                        if (contextNameNodeMap.size() > Constants.MAX_CONTEXT_NAME_SIZE) {
                            setNullContext();
                            return NULL_CONTEXT;
                        } else {
                            node = new EntranceNode(new StringResourceWrapper(name, EntryType.IN), null);
                            // Add entrance node.
                            Constants.ROOT.addChild(node);

                            Map<String, DefaultNode> newMap = new HashMap<>(contextNameNodeMap.size() + 1);
                            newMap.putAll(contextNameNodeMap);
                            newMap.put(name, node);
                            contextNameNodeMap = newMap;
                        }
                    }
                } finally {
                    LOCK.unlock();
                }
            }
        }
        context = new Context(node, name);
        context.setOrigin(origin);
        contextHolder.set(context);
    }

    return context;
}
```

这里的逻辑还是比较简单的

1. 首先在ThreadLocal获取，获取不到就创建，不然就返回
2. 然后再Map中根据ContextName找一个Node
3. 没有找到Node就加锁的方式，创建一个EntranceNode，然后放入Map中
4. 创建Context，设置node，name，origin，再放入ThreadLocal中

到此Context就创建完成

目前Context对象的状态如下图

![](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/Sentinel/20201213092146.jpg)

### 2.lookProcessChain

构建一个slot链，链路的组成为

> DefaultProcessorSlotChain -> NodeSelectorSlot -> ClusterBuilderSlot -> LogSlot -> StatisticSlot -> AuthoritySlot -> SystemSlot -> ParamFlowSlot -> FlowSlot -> DegradeSlot

```java
ProcessorSlot<Object> lookProcessChain(ResourceWrapper resourceWrapper) {
    ProcessorSlotChain chain = chainMap.get(resourceWrapper);
    if (chain == null) {
        synchronized (LOCK) {
            chain = chainMap.get(resourceWrapper);
            if (chain == null) { // 双重校验锁
                // chainMap大小大于一个值，也就是entry数量大小限制了，一个chain对应一个entry
                if (chainMap.size() >= Constants.MAX_SLOT_CHAIN_SIZE) {
                    return null;
                }
				// 构建一个slot chain
                chain = SlotChainProvider.newSlotChain();
                // 这里是逻辑是，新建一个Map大小是oldMap + 1
                Map<ResourceWrapper, ProcessorSlotChain> newMap = new HashMap<ResourceWrapper, ProcessorSlotChain>(chainMap.size() + 1);
                // 然后先整体放入oldMap，再放新建的chain
                newMap.putAll(chainMap);
                newMap.put(resourceWrapper, chain); // 添加到newMap， 这里应该是考虑避免频繁扩容
                chainMap = newMap;
            }
        }
    }
    return chain;
}
```

#### SlotChainProvider.newSlotChain

```java
public static ProcessorSlotChain newSlotChain() {
    if (slotChainBuilder != null) {
        return slotChainBuilder.build();
    }

    // Resolve the slot chain builder SPI.
    slotChainBuilder = SpiLoader.loadFirstInstanceOrDefault(SlotChainBuilder.class, DefaultSlotChainBuilder.class);

    if (slotChainBuilder == null) {
        // Should not go through here.
        RecordLog.warn("[SlotChainProvider] Wrong state when resolving slot chain builder, using default");
        slotChainBuilder = new DefaultSlotChainBuilder();
    } else {
        RecordLog.info("[SlotChainProvider] Global slot chain builder resolved: "
                       + slotChainBuilder.getClass().getCanonicalName());
    }
    return slotChainBuilder.build();
}
```

> com.alibaba.csp.sentinel.slots.DefaultSlotChainBuilder

```java
public class DefaultSlotChainBuilder implements SlotChainBuilder {
    @Override
    public ProcessorSlotChain build() {
        ProcessorSlotChain chain = new DefaultProcessorSlotChain();
        chain.addLast(new NodeSelectorSlot());
        chain.addLast(new ClusterBuilderSlot());
        chain.addLast(new LogSlot());
        chain.addLast(new StatisticSlot());
        chain.addLast(new AuthoritySlot());
        chain.addLast(new SystemSlot());
        chain.addLast(new FlowSlot());
        chain.addLast(new DegradeSlot());
        return chain;
    }
}
```

### 3.创建Entry

```java
Entry e = new CtEntry(resourceWrapper, chain, context);
```

```java
CtEntry(ResourceWrapper resourceWrapper, ProcessorSlot<Object> chain, Context context) {
    super(resourceWrapper);
    this.chain = chain;
    this.context = context;

    setUpEntryFor(context);
}

private void setUpEntryFor(Context context) {
    // The entry should not be associated to NullContext.
    if (context instanceof NullContext) {
        return;
    }
    this.parent = context.getCurEntry();
    if (parent != null) {
        ((CtEntry)parent).child = this;
    }
    context.setCurEntry(this);
}
```

当第一次Entry生成的时候，context.getCurEntry必定是NULL，那么直接执行Context.setCurEntry方法

然后这个Context的状态如下图

![](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/Sentinel/20201213092609.jpg)

### 4.chain.entry （整体流程）

从上面可以看出，chain的对象是 DefaultProcessorSlotChain

```java
public class DefaultProcessorSlotChain extends ProcessorSlotChain {
	// 调用链
    AbstractLinkedProcessorSlot<?> first = new AbstractLinkedProcessorSlot<Object>() {
        @Override
        public void entry(Context context, ResourceWrapper resourceWrapper, Object t, int count, boolean prioritized, Object... args)
            throws Throwable {
            super.fireEntry(context, resourceWrapper, t, count, prioritized, args);
        }
        @Override
        public void exit(Context context, ResourceWrapper resourceWrapper, int count, Object... args) {
            super.fireExit(context, resourceWrapper, count, args);
        }

    };
    AbstractLinkedProcessorSlot<?> end = first;

    @Override
    public void addFirst(AbstractLinkedProcessorSlot<?> protocolProcessor) {
        protocolProcessor.setNext(first.getNext());
        first.setNext(protocolProcessor);
        if (end == first) {
            end = protocolProcessor;
        }
    }

    // 存储处理链路
    @Override
    public void addLast(AbstractLinkedProcessorSlot<?> protocolProcessor) {
        end.setNext(protocolProcessor);
        end = protocolProcessor;
    }
	// 执行下一个处理器
    @Override
    public void entry(Context context, ResourceWrapper resourceWrapper, Object t, int count, boolean prioritized, Object... args)
        throws Throwable {
        // 第一次执行时，这里的first是NodeSelectorSlot
        first.transformEntry(context, resourceWrapper, t, count, prioritized, args);
    }
    
}
```

#### first.transformEntry 

> com.alibaba.csp.sentinel.slotchain.AbstractLinkedProcessorSlot#transformEntry

```java
void transformEntry(Context context, ResourceWrapper resourceWrapper, Object o, int count, boolean prioritized, Object... args)
    throws Throwable {
    T t = (T)o;
    entry(context, resourceWrapper, t, count, prioritized, args); // 调用各个子类处理逻辑
}
```



整体的执行流程如下。

- NodeSelectorSlot：负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级
- ClusterBuilderSlot：则用于存储资源的统计信息以及调用者信息，例如该资源的 RT, QPS, thread count 等等，这些信息将用作为多维度限流，降级的依据
- LogSlot：用于记录日志。 
- StatisticSlot：则用于记录，统计不同维度的 runtime 信息
- AuthoritySlot：则根据黑白名单，来做黑白名单控制
- SystemSlot：用于验证系统级别的规则。 
- FlowSlot：实现限流机制。 
- DegradeSlot：实现熔断机制。

### 5.NodeSelectorSlot

这个类主要用于构建调用链，这个需要讲解一下，在后续过程中会比较关键，代码如下。

```java
@Override
public void entry(Context context, ResourceWrapper resourceWrapper, Object obj, int count, boolean prioritized, Object... args) throws Throwable {
    
    DefaultNode node = map.get(context.getName());
    if (node == null) {
        synchronized (this) {
            node = map.get(context.getName());
            if (node == null) {
                node = new DefaultNode(resourceWrapper, null); // 创建DefaultNode
                // 下面这些逻辑是放入map的逻辑，因为后期map比较大，所以这样放入，性能会高一些
                HashMap<String, DefaultNode> cacheMap = new HashMap<String, DefaultNode>(map.size());
                cacheMap.putAll(map);
                cacheMap.put(context.getName(), node);
                map = cacheMap;
                // 关键在这，这是修改调用链树的地方
                ((DefaultNode) context.getLastNode()).addChild(node);
            }

        }
    }
	// 替换context中的curEntry中的curNode
    context.setCurNode(node);
    fireEntry(context, resourceWrapper, node, count, prioritized, args);
}
```

这里有几个对象要单独说明：

- context：表示上下文，一个线程对应一个context，其中包含一些属性如下
  - name：名字 
  - entranceNode：调用链入口 
  - curEntry：当前entry 
  - origin：调用者来源 
  - async：异步
- Node： 表示一个节点，这个节点会保存某个资源的各个实时统计数据，通过访问某个节点，就可 以获得对应资源的实时状态，根据这个信息来进行限流和降级，它有几种节点类型
  - StatisticNode：统计节点 
  - DefaultNode：默认节点，NodeSelectorSlot中创建的就是这个节点 
  - ClusterNode：集群节点 
  - EntranceNode：该节点表示一棵调用链树的入口节点，通过他可以获取调用链树中所有的子节点

NodeSelectorSlot运行结束之后，context的初始结构如下图所示，其中两个Node指向的是同一个对象。

https://blog.csdn.net/qq_33330687/article/details/86567955



### 6.StatisticSlot

在整个slot链路中，比较重要的，就是流量数据统计以及流量规则检测这两个slot，我们先来分析一下 StatisticSlot这个对象。

`StatisticSlot` 是 Sentinel 的核心功能插槽之一，用于统计实时的调用数据。

- `clusterNode` ：资源唯一标识的 ClusterNode 的 runtime 统计 
- `origin` ：根据来自不同调用者的统计信息 
- `defaultnode` : 根据上下文条目名称和资源 ID 的 runtime 统计 
- 入口的统计

```java
@Override
public void entry(Context context, 
                  ResourceWrapper resourceWrapper, 
                  DefaultNode node, 
                  int count,
                  boolean prioritized, 
                  Object... args) throws Throwable {
    try {
        // 先交由后续的限流&降级等processorSlot处理，然后根据处理结果进行统计
		// Sentinel责任链的精华（不使用 for 循环遍历调用 ProcessorSlot 的原因）
        fireEntry(context, resourceWrapper, node, count, prioritized, args);

        // Request passed, add thread count and pass count.
        node.increaseThreadNum();  // 当前节点的请求线程数加1
        node.addPassRequest(count);
		
        // 针对不同类型的node记录线程数量和请求通过数量的统计。
        if (context.getCurEntry().getOriginNode() != null) {
            context.getCurEntry().getOriginNode().increaseThreadNum(); // 记录线程数
            context.getCurEntry().getOriginNode().addPassRequest(count); // 记录请求通过数(QPS)
        }

        if (resourceWrapper.getEntryType() == EntryType.IN) {
            // Add count for global inbound entry node for global statistics.
            Constants.ENTRY_NODE.increaseThreadNum();
            Constants.ENTRY_NODE.addPassRequest(count);
        }

        // 可调用 StatisticSlotCallbackRegistry#addEntryCallback 静态方法注册 ProcessorSlotEntryCallback
        for (ProcessorSlotEntryCallback<DefaultNode> handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) {
            handler.onPass(context, resourceWrapper, node, count, args);
        }
        // 优先级等待异常，这个在FlowRule中会有涉及到。
    } catch (PriorityWaitException ex) {
        node.increaseThreadNum();
        if (context.getCurEntry().getOriginNode() != null) {
            // Add count for origin node.
            context.getCurEntry().getOriginNode().increaseThreadNum();
        }

        if (resourceWrapper.getEntryType() == EntryType.IN) {
            // Add count for global inbound entry node for global statistics.
            Constants.ENTRY_NODE.increaseThreadNum();
        }
        // Handle pass event with registered entry callback handlers.
        for (ProcessorSlotEntryCallback<DefaultNode> handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) {
            handler.onPass(context, resourceWrapper, node, count, args);
        }
    } catch (BlockException e) {
        // Blocked, set block exception to current entry.
        context.getCurEntry().setError(e); // 设置限流异常到当前entry中

        // Add block count.
        node.increaseBlockQps(count); // 增加被限流的数量
        // 根据不同Node类型增加阻塞限流的次数
        if (context.getCurEntry().getOriginNode() != null) {
            context.getCurEntry().getOriginNode().increaseBlockQps(count);
        }

        if (resourceWrapper.getEntryType() == EntryType.IN) {
            // Add count for global inbound entry node for global statistics.
            Constants.ENTRY_NODE.increaseBlockQps(count);
        }

        // Handle block event with registered entry callback handlers.
        for (ProcessorSlotEntryCallback<DefaultNode> handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) {
            handler.onBlocked(e, context, resourceWrapper, node, count, args);
        }

        throw e;
    } catch (Throwable e) {
        // Unexpected error, set error to current entry.
        context.getCurEntry().setError(e);

        // This should not happen.
        node.increaseExceptionQps(count);
        if (context.getCurEntry().getOriginNode() != null) {
            context.getCurEntry().getOriginNode().increaseExceptionQps(count);
        }

        if (resourceWrapper.getEntryType() == EntryType.IN) {
            Constants.ENTRY_NODE.increaseExceptionQps(count);
        }
        throw e;
    }
}
```

仔细观察这段代码可以看到，StatisticSlot会分别对线程数和QPS进行递增，这个递增操作会涉及到不 同纬度的请求数量的统计。

```java
node.increaseThreadNum(); // 当前节点的请求线程数加1
node.addPassRequest(count);
```

#### node.addPassRequest (DefaultNode.addPassRequest)

```java
@Override
public void addPassRequest(int count) {
    // 调用父类（StatisticNode）来进行统计
    super.addPassRequest(count);
    // 根据 clusterNode 汇总统计（背后也是调用父类StatisticNode）
    this.clusterNode.addPassRequest(count);
}
```

#### StatisticNode.addPassRequest

分别调用两个时间窗口来递增请求数量。 

内部实际调用的是ArrayMetric来进行请求数量的统计

```java
// 按照秒来统计，分成两个窗口，每个窗口500ms，用来统计QPS   new ArrayMetric(2, 1000)
private transient volatile Metric rollingCounterInSecond = new ArrayMetric(SampleCountProperty.SAMPLE_COUNT, IntervalProperty.INTERVAL);

// 按照分钟统计，生成60个窗口，每个窗口1000ms
private transient Metric rollingCounterInMinute = new ArrayMetric(60, 60 * 1000, false);

@Override
public void addPassRequest(int count) {
    rollingCounterInSecond.addPass(count);
    rollingCounterInMinute.addPass(count);
}
```

这里采用的是滑动窗口的方式来记录请求的次数。

### 7.滑动窗口设计

#### 滑动窗口有关的核心类图

![](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/Sentinel/20201209100402.jpg)

整个类的关系图实际上是比较清晰的，ArrayMetric实际上是一个包装类，内部通过LeapArray来实现具体的统计逻辑，而LeapArray中维护了多个WindowWrap（滑动窗口），而WindowWrap中采用了 MetricBucket来进行指标数据的统计。

- Metric 指标收集的接口，定义滑动窗口中成功数量、异常数量、阻塞数量、TPS、响应时间等数据 
- ArrayMetric 滑动窗口核心实现类 
- LeapArray 装载滑动窗口的数组
- WindowWrap 每一个滑动窗口的包装类，内部的数据结构采用MetricBucket 
- MetricBucket 表示指标桶，包含阻塞数量、异常数量、成功数、响应时间等 
- MetricEvent 指标类型，通过数、阻塞数、异常数、成功数等

#### ArrayMetric.addPass

继续沿着代码往下看，进入到ArrayMetric.addPass方法。 

- 从LeapArray中根据得到当前时间点对应的窗口 
- 调用MetricBucket中的addPass方法，增加当前窗口中的统计次数

```java
private final LeapArray<MetricBucket> data;

/**
 *
 * 
 * @param sampleCount 窗口数
 * @param intervalInMs 窗口时间
 */
public ArrayMetric(int sampleCount, int intervalInMs) {
    // OccupiableBucketLeapArray 可以借用未来一个采样区间
    this.data = new OccupiableBucketLeapArray(sampleCount, intervalInMs);
}

public ArrayMetric(int sampleCount, int intervalInMs, boolean enableOccupy) {
    if (enableOccupy) {
        this.data = new OccupiableBucketLeapArray(sampleCount, intervalInMs);
    } else {
        this.data = new BucketLeapArray(sampleCount, intervalInMs);
    }
}

@Override
public void addPass(int count) {
    WindowWrap<MetricBucket> wrap = data.currentWindow();
    wrap.value().addPass(count);
}
```

其中，data对象的实例是，sampleCount=2 , intervalInMs=1000ms。 

这两个参数表示，滑动窗口的大小是2个，每一个滑动窗口的时间单位是500ms

```java
public ArrayMetric(int sampleCount, int intervalInMs) {
    this.data = new OccupiableBucketLeapArray(sampleCount, intervalInMs);
}
```

OccupiableBucketLeapArray: 实现的思想是当前抽样统计中的“令牌”已耗尽，即达到用户设定的相关指标的阔值后，可以向下一个时间窗口，即借用未来一个采样区间。

```java
public OccupiableBucketLeapArray(int sampleCount, int intervalInMs) {
    // This class is the original "CombinedBucketArray".
    super(sampleCount, intervalInMs);
    this.borrowArray = new FutureBucketLeapArray(sampleCount, intervalInMs);
}
```



#### **super(sampleCount, intervalInMs);**

```java
public LeapArray(int sampleCount, int intervalInMs) {
    AssertUtil.isTrue(sampleCount > 0, "bucket count is invalid: " + sampleCount);
    AssertUtil.isTrue(intervalInMs > 0, "total time interval of the sliding window should be positive");
    AssertUtil.isTrue(intervalInMs % sampleCount == 0, "time span needs to be evenly divided");

    this.windowLengthInMs = intervalInMs / sampleCount; // 时间窗口大小  单位ms
    this.intervalInMs = intervalInMs; // 统计的时间间隔 intervalInMs = windowLengthInMs * sampleCount
    this.sampleCount = sampleCount; // 窗口数

    this.array = new AtomicReferenceArray<>(sampleCount);
}
```

#### 滑动窗口初始化之后的形态

在以秒为单位的时间窗口中，会初始化两个长度的数组： AtomicReferenceArray<> array ，这个数组表示滑动窗口的大小。 

其中，每个窗口会占用500ms的时间。

#### LeapArray.currentWindow

根据当前时间，从滑动窗口中获得指定的WindowWrap对象，然后更新对应的各项指标。由于后续做限 流规则判断的时候使用。

> 调用过程：com.alibaba.csp.sentinel.node.StatisticNode#addPassRequest -> com.alibaba.csp.sentinel.slots.statistic.metric.ArrayMetric#addPass -> com.alibaba.csp.sentinel.slots.statistic.base.LeapArray#currentWindow

```java
public WindowWrap<T> currentWindow() {
    return currentWindow(TimeUtil.currentTimeMillis());
}

/**
 * @param timeMillis 当前时间
 */
private int calculateTimeIdx(long timeMillis) {
    long timeId = timeMillis / windowLengthInMs; // timeId = 当前时间 / 时间窗口大小
    return (int)(timeId % array.length()); // 去摸
}

protected long calculateWindowStart(long timeMillis) {
    return timeMillis - timeMillis % windowLengthInMs;
}

/**
 * @param timeMillis 当前时间
 */
public WindowWrap<T> currentWindow(long timeMillis) {
    if (timeMillis < 0) {
        return null;
    }
	// 计算当前时间在滑动窗口中的索引，计算方式比较简单，当前时间除以单个时间窗口的时间长度，再从整个时间窗口长度进行取模
    int idx = calculateTimeIdx(timeMillis);
    // 计算当前时间在时间窗口中的开始时间
    long windowStart = calculateWindowStart(timeMillis);

    /*
    * Get bucket item at given time from the array.
    *
    * (1) 如果没有Bucket，那么只需创建一个新的Bucket并将CAS更新为循环数组。
    * (2) 桶是最新的，然后返回桶。
    * (3) 桶被弃用，然后重置当前桶并清除所有弃用的桶。
    */
    while (true) {
        WindowWrap<T> old = array.get(idx); // 通过索引找到制定的窗口
        if (old == null) { // 如果为空，说明此处还未初始化
            /*
            *     B0       B1      B2    NULL      B4
            * ||_______|_______|_______|_______|_______||___
            * 200     400     600     800     1000    1200  timestamp
            *                             ^
            *                          time=888
            *            bucket is empty, so create new and update
            *
            * If the old bucket is absent, then we create a new bucket at {@code windowStart},
            * then try to update circular array via a CAS operation. Only one thread can
            * succeed to update, while other threads yield its time slice.
            */
            // 构建一个新的windowWrap对象
            WindowWrap<T> window = new WindowWrap<T>(windowLengthInMs, windowStart, newEmptyBucket(timeMillis));
            if (array.compareAndSet(idx, null, window)) { // 通过cas操作替换到array窗口数组中。
                // Successfully updated, return the created bucket.
                return window;  // 更新成功，直接返回
            } else {
                // Contention failed, the thread will yield its time slice to wait for bucket available.
                Thread.yield();
            }
        } else if (windowStart == old.windowStart()) { // 如果windowStart得到的窗口就是当前索引位置的窗口，则直接把该位置的窗口返回
            /*
            *     B0       B1      B2     B3      B4
            * ||_______|_______|_______|_______|_______||___
            * 200     400     600     800     1000    1200  timestamp
            *                             ^
            *                          time=888
            *            startTime of Bucket 3: 800, so it's up-to-date
            *
            * If current {@code windowStart} is equal to the start timestamp of old bucket,
            * that means the time is within the bucket, so directly return the bucket.
            */
            return old;
        } else if (windowStart > old.windowStart()) { // 如果大于，则表示应该在下一个滑动窗口中。
            /*
            *   (old)
            *             B0       B1      B2    NULL      B4
            * |_______||_______|_______|_______|_______|_______||___
            * ...    1200     1400    1600    1800    2000    2200  timestamp
            *                              ^
            *                           time=1676
            *          startTime of Bucket 2: 400, deprecated, should be reset
            *
            * If the start timestamp of old bucket is behind provided time, that means
            * the bucket is deprecated. We have to reset the bucket to current {@code windowStart}.
            * Note that the reset and clean-up operations are hard to be atomic,
            * so we need a update lock to guarantee the correctness of bucket update.
            *
            * The update lock is conditional (tiny scope) and will take effect only when
            * bucket is deprecated, so in most cases it won't lead to performance loss.
            */
            if (updateLock.tryLock()) { // 加锁，并重置MetricBucket
                try {
                    // Successfully get the update lock, now we reset the bucket.
                    // 成功获得更新锁，现在我们重置桶。
                    return resetWindowTo(old, windowStart);
                } finally {
                    updateLock.unlock();
                }
            } else {
                // Contention failed, the thread will yield its time slice to wait for bucket available.
                Thread.yield();
            }
        } else if (windowStart < old.windowStart()) { // 异常情况
            // Should not go through here, as the provided time is already behind.
            return new WindowWrap<T>(windowLengthInMs, windowStart, newEmptyBucket(timeMillis));
        }
    }
}

// 重置桶
@Override
protected WindowWrap<MetricBucket> resetWindowTo(WindowWrap<MetricBucket> w, long time) {
    // Update the start time and reset value.
    w.resetTo(time);
    MetricBucket borrowBucket = borrowArray.getWindowValue(time);
    if (borrowBucket != null) {
        w.value().reset();
        w.value().addPass((int)borrowBucket.pass());
    } else {
        w.value().reset();
    }

    return w;
}
```



#### MetricBucket.add

> 调用流程：com.alibaba.csp.sentinel.slots.statistic.metric.ArrayMetric#addPass -> com.alibaba.csp.sentinel.slots.statistic.data.MetricBucket#addPass -> com.alibaba.csp.sentinel.slots.statistic.data.MetricBucket#add
>
> 
>
> com.alibaba.csp.sentinel.slots.statistic.data.MetricBucket#add

```java
public MetricBucket() {
    MetricEvent[] events = MetricEvent.values(); // 获得 MetricEvent 所有枚举
    this.counters = new LongAdder[events.length]; // 分配执行长度数组
    for (MetricEvent event : events) {
        counters[event.ordinal()] = new LongAdder();
    }
    initMinRt();
}

// counters的数组长度是6，其中event.ordinal表示MetricEvent，那么这里记录的就是，根据MetricEvent统计指定Event的次数
public MetricBucket add(MetricEvent event, long n) {
    counters[event.ordinal()].add(n); // 对指定的MetricEvent枚举下标添加数据  例如：MetricEvent.PASS的下标是0，就往counters[0].add(n)
    return this;
}
```

#### LongAdder.add

这段代码不知道大家是否熟悉，就是ConcurrentHashMap里面，用来记录请求数量的操作，也就是采 用分段锁的方式来做计数处理，从而提升整体的性能。

> com.alibaba.csp.sentinel.slots.statistic.base.LongAdder#add

```java
public void add(long x) {
    Cell[] as;
    long b, v;
    HashCode hc;
    Cell a;
    int n;
    if ((as = cells) != null || !casBase(b = base, b + x)) { // 尝试直接 在base上添加x，如不成功，则出现并发情况，需要并发处理
        boolean uncontended = true;
        int h = (hc = threadHashCode.get()).code;
        if (as == null || 
            (n = as.length) < 1 ||
            (a = as[(n - 1) & h]) == null ||
            !(uncontended = a.cas(v = a.value, v + x)))  // 再次尝试从cells的其中一个cell中进行加x，采用分段乐观锁
        { 
            // 如果还是添加添加失败，执行retryUpdate
            retryUpdate(x, hc, uncontended); 
        }
    }
}

final void retryUpdate(long x, HashCode hc, boolean wasUncontended) {
    int h = hc.code;
    boolean collide = false;                // True if last slot nonempty
    for (;;) {
        Cell[] as;
        Cell a;
        int n;
        long v;
        if ((as = cells) != null && (n = as.length) > 0) {
            if ((a = as[(n - 1) & h]) == null) { // 指定cell的值为空，执行创建cell对象
                if (busy == 0) {            // Try to attach new Cell
                    Cell r = new Cell(x);   // Optimistically create
                    if (busy == 0 && casBusy()) {
                        boolean created = false;
                        try {               // Recheck under lock
                            Cell[] rs;
                            int m, j;
                            if ((rs = cells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & h] == null) {
                                rs[j] = r;
                                created = true;
                            }
                        } finally {
                            busy = 0;
                        }
                        if (created) { break; }
                        continue;           // Slot is now non-empty
                    }
                }
                collide = false;
            } else if (!wasUncontended) {      // CAS already known to fail
                wasUncontended = true;      // Continue after rehash
            } else if (a.cas(v = a.value, fn(v, x))) { break; } else if (n >= NCPU || cells != as) {
                collide = false;            // At max size or stale
            } else if (!collide) { collide = true; } else if (busy == 0 && casBusy()) {
                try {
                    if (cells == as) {      // Expand table unless stale
                        Cell[] rs = new Cell[n << 1];
                        for (int i = 0; i < n; ++i) { rs[i] = as[i]; }
                        cells = rs;
                    }
                } finally {
                    busy = 0;
                }
                collide = false;
                continue;                   // Retry with expanded table
            }
            h ^= h << 13;                   // Rehash
            h ^= h >>> 17;
            h ^= h << 5;
        } else if (busy == 0 && cells == as && casBusy()) {
            boolean init = false;
            try {                           // Initialize table
                if (cells == as) {
                    Cell[] rs = new Cell[2];
                    rs[h & 1] = new Cell(x);
                    cells = rs;
                    init = true;
                }
            } finally {
                busy = 0;
            }
            if (init) { break; }
        } else if (casBase(v = base, fn(v, x))) {
            break;                          // Fall back on using base
        }
    }
    hc.code = h;                            // Record index for next time
}
```

### 8.FlowSlot

这个 slot 主要根据预设的资源的统计信息，按照固定的次序，依次生效。如果一个资源对应两条或者多条流控规则，则会根据如下次序依次检验，直到全部通过或者有一个规则生效为止: 

- 指定应用生效的规则，即针对调用方限流的；
- 调用方为 other 的规则；
- 调用方为 default 的规则。

```java
FlowSlot(FlowRuleChecker checker) {
    AssertUtil.notNull(checker, "flow checker should not be null");
    this.checker = checker;
}

@Override
public void entry(Context context, 
                  ResourceWrapper resourceWrapper, 
                  DefaultNode node, 
                  int count,
                  boolean prioritized,  // 如果是高优先级请求，并且限流类型为qps，则在系统不会立即失败，会借用未来的时间窗口进行统计，然后放行
                  Object... args) throws Throwable {
    
    checkFlow(resourceWrapper, context, node, count, prioritized);

    fireEntry(context, resourceWrapper, node, count, prioritized, args);
}
```

#### checkFlow

进入到FlowRuleChecker.checkFlow方法中。 

- 根据资源名称，找到限流规则列表 
- 如果限流规则不为空，则遍历规则，调用canPassCheck方法进行校验。

```java
public void checkFlow(Function<String, Collection<FlowRule>> ruleProvider, 
                      ResourceWrapper resource,
                      Context context, 
                      DefaultNode node, 
                      int count, 
                      boolean prioritized) throws BlockException {
    
    if (ruleProvider == null || resource == null) {
        return;
    }
    Collection<FlowRule> rules = ruleProvider.apply(resource.getName());
    if (rules != null) {
        for (FlowRule rule : rules) {
            if (!canPassCheck(rule, context, node, count, prioritized)) {
                throw new FlowException(rule.getLimitApp(), rule);
            }
        }
    }
}
```

### canPassCheck

判断是否是集群限流模式，如果是，则走passClusterCheck，否则，调用passLocalCheck方法。

```java
public boolean canPassCheck(FlowRule rule, 
                            Context context, 
                            DefaultNode node, 
                            int acquireCount,
                            boolean prioritized) {
    
    String limitApp = rule.getLimitApp();
    if (limitApp == null) {
        return true;
    }

    if (rule.isClusterMode()) { // 判断是否是集群限流模式
        return passClusterCheck(rule, context, node, acquireCount, prioritized);
    }
    return passLocalCheck(rule, context, node, acquireCount, prioritized);
}
```

### passLocalCheck

- selectNodeByRequesterAndStrategy，根据请求和策略来获得Node 
- rule.getRater(), 根据不同的限流控制行为来，调用canPass进行校验。

```java
private static boolean passLocalCheck(FlowRule rule, 
                                      Context context, 
                                      DefaultNode node, 
                                      int acquireCount,
                                      boolean prioritized) {
    // 根据请求和策略来获得Node
    Node selectedNode = selectNodeByRequesterAndStrategy(rule, context, node);
    if (selectedNode == null) {
        return true;
    }
    return rule.getRater().canPass(selectedNode, acquireCount, prioritized);
}
```

### DefaultController.canPass

通过默认的限流行为（直接拒绝），进行限流判断。

```java
@Override
public boolean canPass(Node node, int acquireCount, boolean prioritized) {
    // 先根据node获取资源当前的使用数量，这里会根据qps或者并发数策略来获得相关的值
    int curCount = avgUsedTokens(node);
    // 当前已使用的请求数加上本次请求的数量是否大于阈值
    if (curCount + acquireCount > count) { // 如果为true，说明应该被限流
        // 如果此请求是一个高优先级请求，并且限流类型为qps，则不会立即失败，而是去占用未来的时间窗口，等到下一个时间窗口通过请求。
        if (prioritized && grade == RuleConstant.FLOW_GRADE_QPS) {
            long currentTime;
            long waitInMs;
            currentTime = TimeUtil.currentTimeMillis();
            waitInMs = node.tryOccupyNext(currentTime, acquireCount, count);
            if (waitInMs < OccupyTimeoutProperty.getOccupyTimeout()) {
                node.addWaitingRequest(currentTime + waitInMs, acquireCount);
                node.addOccupiedPass(acquireCount);
                sleep(waitInMs);

                // PriorityWaitException indicates that the request will pass after waiting for {@link @waitInMs}.
                throw new PriorityWaitException(waitInMs);
            }
        }
        return false;
    }
    return true;
}
```

一旦被拒绝，则抛出 FlowException 异常。

其他处理方式：

- RateLimiterController 匀速队列（令牌桶方式）
- WarmUpController  冷启动
- WarmUpRateLimiterController  冷启动 + 匀速队列

![](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/Sentinel/20201209143526.jpg)

### PriorityWait （OccupiableBucketLeapArray数组，借用未来窗口）

在DefaultController.canPass中，调用如下代码去借后续的窗口

```java
node.addWaitingRequest(currentTime + waitInMs, acquireCount);
node.addOccupiedPass(acquireCount);
```

> addWaitingRequest -> ArrayMetric.addWaiting -> OccupiableBucketLeapArray.addWaiting

borrowArray，它是一个FutureBucketLeapArray对象，这里定义的是未来的时间窗口，然后获得未来 时间的窗口去增加计数

> com.alibaba.csp.sentinel.slots.statistic.metric.ArrayMetric#addWaiting

```java
@Override
public void addWaiting(long time, int acquireCount) {
    data.addWaiting(time, acquireCount);
}
```

> com.alibaba.csp.sentinel.slots.statistic.metric.occupy.OccupiableBucketLeapArray#addWaiting

```java
@Override
public void addWaiting(long time, int acquireCount) {
    WindowWrap<MetricBucket> window = borrowArray.currentWindow(time);
    window.value().add(MetricEvent.PASS, acquireCount);
}
```

最终，在StatisticSlot.entry中，捕获异常 

如果存在优先级比较高的任务，并且当前的请求已经达到阈值，抛出这个异常，实际上是去占用未来的 一个时间窗口去进行计数，抛出这个异常之后，会进入到StatisticSlot中进行捕获。然后直接通过

> com.alibaba.csp.sentinel.slots.statistic.StatisticSlot#entry

```java
@Override
public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count,
                  boolean prioritized, Object... args) throws Throwable {
    try {
        // 代码省略...
    } catch (PriorityWaitException ex) {
        node.increaseThreadNum();
        if (context.getCurEntry().getOriginNode() != null) {
            // Add count for origin node.
            context.getCurEntry().getOriginNode().increaseThreadNum();
        }

        if (resourceWrapper.getEntryType() == EntryType.IN) {
            // Add count for global inbound entry node for global statistics.
            Constants.ENTRY_NODE.increaseThreadNum();
        }
        // Handle pass event with registered entry callback handlers.
        for (ProcessorSlotEntryCallback<DefaultNode> handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) {
            handler.onPass(context, resourceWrapper, node, count, args);
        }
    } catch (BlockException e) {
        // 代码省略...
```

### 集群限流原理

集群限流，每次会发起一个请求到token-server端进行限流判断。

### FlowRuleChecker.passClusterCheck

> com.alibaba.csp.sentinel.slots.block.flow.FlowRuleChecker#passClusterCheck

```java
private static boolean passClusterCheck(FlowRule rule, 
                                        Context context, 
                                        DefaultNode node, 
                                        int acquireCount,
                                        boolean prioritized) {
    
    try {
        // 获取Sentinel服务节点
        TokenService clusterService = pickClusterService();
        if (clusterService == null) { // 如果没有配置Sentinel服务节点，采用本地限流
            return fallbackToLocalOrPass(rule, context, node, acquireCount, prioritized);
        }
        long flowId = rule.getClusterConfig().getFlowId();
        // 调用远程Sentinel服务 获得放行权
        TokenResult result = clusterService.requestToken(flowId, acquireCount, prioritized);
        return applyTokenResult(result, rule, context, node, acquireCount, prioritized);
        // If client is absent, then fallback to local mode.
    } catch (Throwable ex) {
        RecordLog.warn("[FlowRuleChecker] Request cluster token unexpected failed", ex);
    }
    // Fallback to local flow control when token client or server for this rule is not available.
    // If fallback is not enabled, then directly pass.
    return fallbackToLocalOrPass(rule, context, node, acquireCount, prioritized);
}
```

