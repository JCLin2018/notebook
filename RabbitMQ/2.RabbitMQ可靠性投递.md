# RabbitMQ可靠性投递

## 1.可靠性投递

一个经典的面试题：在使用MQ实现异步通信的过程中，有消息丢了怎么办?或者MQ消息重复了怎么办?

当然，RabbitMQ在设计的时候其实就考虑了这一点，提供了很多保证消息可靠投递的机制。这个可以说是RabbitMQ比较突出的一个特性。

可靠性只是问题的一个方面，发送消息的效率同样是我们需要考虑的问题，而这两个因素是无法兼得的。如果在发送消息的每一个环节都采取相关措施来保证可靠性，势必会对消息的收发效率造成影响。

所以，这些手段大家都可以用，但并不是一定要用。

例如：一些业务实时一致性要求不是特别高的场合，可以牺牲一些可靠性来换取效率。比如发送通知或者记录日志的这种场景，如果用户没有收到通知，不会造成很大的影响，就不需要严格保证所有的消息都发送成功。如果失败了，只要再次发送就可以了。

下面，我们会根据上节课讲的RabbitMQ的工作模型，来分析一下RabbitMQ为我们提供了哪些可靠性措施。

![image-20210509152514716](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/rabbitmq/20210509152516.png)

在我们使用RabbitMQ收发消息的时候，有几个主要环节：

1. 代表消息从生产者发送到Broker

   生产者把消息发到Broker之后，怎么知道自己的消息有没有被Broker成功接收?如果Broker不给应答，生产者不断地发送，那有可能是一厢情愿，消息全部进了黑洞。

2. 代表消息从Exchange路由到Queue

   Exchange是一个绑定列表，它的职责是分发消息。如果它没有办法履行它的职责怎么办?也就是说，找不到队列或者找不到正确的队列，怎么处理?

3. 代表消息在Queue中存储

   队列有自己的数据库(Mnesia) ，它是真正用来存储消息的。如果还没有消费者来消费，那么消息要一直存储在队列里面。你的信件放在邮局，如果邮局内部出了问题，比如起火，信件肯定会丢失。怎么保证消息在队列稳定地存储呢?

4. 代表消费者订阅Queue并消费消息

   队列的特性是什么?FIFO。队列里面的消息是一条一条的投递的，也就是说，只有上一条消息被消费者接收以后，才能把这一条消息从数据库删掉，继续投递下一条消息。

或者反过来说，如果消费者不签收，我是不能去派送下一个快件的，总不能丢在门口就跑吧?

问题来了，Broker(快递总部) 怎么知道消费者已经接收了消息呢?

下面我们就从这四个环节入手，分析如何保证消息的可靠性。

### 1.1消息发送到RabbitMQ服务器

第一个环节是生产者发送消息到Broker。先来说一下什么情况下会发送消息失败?

可能因为网络连接或者Broker的问题(比如硬盘故障、硬盘写满了) 导致消息发送失败，生产者不能确定Broker有没有正确的接收。

如果我们去设计，肯定要给生产者发送消息的接口一个应答，生产者才可以明确知道消息有没有发送成功。

在RabbitMQ里面提供了两种机制服务端确认机制，也就是在生产者发送消息给RabbitMQ的服务端的时候，服务端会通过某种方式返回一个应答，只要生产者收到了这个应答，就知道消息发送成功了。

第一种是Transaction(事务) 模式，第二种Confirm(确认) 模式。

**Transaction(事务) 模式**

事务模式怎么使用呢?它在创建channel的时候，可以把信道设置成事务模式，然后就可以发布消息给RabbitMQ了。如果channe.tx Commit() ； 的方法调用成功，就说明事务提交成功，则消息一定到达了RabbitMQ中。

```java
try {
  channel.txSelect();
  // 发送消息
  // String Exchange，String routingKey，BasicProperties props，byte[] body
  channel.basicPublish("", QUEUE_NAME, nul, (msg).getBytes());
  // int i = 1/0;
  channel.txCommit();
  System.out.println("消息发送成功");
} catch (Exception e) {
  channel.txRollback();
  System.out.println("消息已经回滚");
}
```

如果在事务提交执行之前由于RabbitMQ异常崩溃或者其他原因抛出异常，这个时候我们便可以将其捕获，进而通过执行channel.tx Rollback() 方法来实现事务回滚。

![image-20210509153800467](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/rabbitmq/20210509153800.png)

在事务模式里面，只有收到了服务端的Commit-OK的指令，才能提交成功。所以可以解决生产者和服务端确认的问题。但是事务模式有一个缺点，它是阻塞的，一条消息没有发送完毕，不能发送下一条消息，它会榨干RabbitMQ服务器的性能。所以不建
议大家在生产环境使用。

Spring Boot中的设置：

```java
rabbitTemplate.setChannelTransacted(true);
```

那么有没有其他可以保证消息被Broker接收，但是又不大量消耗性能的方式呢?

这个就是第二种模式，叫做确认(Confirm) 模式。

**Confirm(确认) 模式**

确认模式有三种，一种是普通确认模式。

在生产者这边通过调用channel.confirmSelect() 方法将信道设置为Confirm模式，然后发送消息。一旦消息被投递到交换机之后(跟是否路由到队列没有关系) ，RabbitMQ就会发送一个确认(Basic.Ack) 给生产者，也就是调用channel wait For Confirms() 返
回true，这样生产者就知道消息被服务端接收了。

如果网络错误，会抛出连接异常。如果交换机不存在，会抛出404错误。

```java
//开启发送方确认模式
channel.confirmSelect()；
channel.basicPublish("", QUEUE_NAME, null, msg.getBytes()):
//普通Confirm,发送一条，确认一条
if(channel.waitForConfirms()) {
	System.out.println("消息发送成功");
}
```

这种发送1条确认1条的方式消息还不是太高，所以我们还有一种批量确认的方式。批量确认，就是在开启Confirm模式后，先发送一批消息。

```java
try {
  channel.confirmSelect();
  for(int i = 0; i < 5; i++) {
    // 发送消息
    // String exchange，String routingKey，BasicProperties props，byte[] body
    channel.basicPublish("",QUEUE_NAME, null, (msg+ "-" + i).getBytes());
  }
  //批量确认结果，ACK如果是Multiple=True，代表ACK里面的Delivery-Tag之前的消息都被确认了
	//比如5条消息可能只收到1个ACK，也可能收到2个(抓包才看得到)
	//直到所有信息都发布，只要有一个未被Broker确认就会IOException
  channel.waitForConfirmsOrDie();
  System.out.println("消息发送完毕，批量确认成功");
} catch(Exception e) {
	//发生异常，可能需要对所有消息进行重发
  e.printStackTrace();
}
```

只要 `channel.waitForConfirmsOrDie();`  方法没有抛出异常，就代表消息都被服务端接收了。

批量确认的方式比单条确认的方式效率要高，但是也有两个问题：

第一个就是批量的数量的确定。对于不同的业务，到底发送多少条消息确认一次?数量太少，效率提升不上去。数量多的话，又会带来另一个问题，比如我们发1000条消息才确认一次，如果前面999条消息都被服务端接收了，如果第1000条消息被拒绝了，
那么前面所有的消息都要重发。

有咩有一种方式，可以一边发送一边确认的呢?这个就是异步确认模式。

异步确认模式需要添加一个ConfirmListener，并且用一个SortedSet来维护一个批次中没有被确认的消息。

```java
//用来维护未确认消息的deliveryTag
final SortedSet<Long> confirmSet = Collections.synchronizedSortedSet(new TreeSet<Long>());

// 这里不会打印所有响应的ACK；ACK可能有多个，有可能一次确认多条，也有可能一次确认一条
// 异步监听确认和未确认的消息
// 如果要重复运行，先停掉之前的生产者，清空队列
channel.addConfirmListener(new Confirm Listener() {
	public void handleNack(long deliveryTag, boolean multiple) throws IOException{
		System.out.println("Broker未确认消息，标识："+deliveryTag);
		if(multiple) {
      //headSet表示后面参数之前的所有元素，全部删除
			confirmSet.headSet(deliveryTag + 1L).clear();
		} else {
			confirmSet.remove(deliveryTag);
    }
    //这里添加重发的方法
  }
	public void handleAck(long deliveryTag, boolean multiple) throws IOException{
		//如果true表示批量执行了deliveryTag这个值以前(小于deliveryTag的) 的所有消息，如果为false的话表示单条确认
		System.out.printIn(String.format("Broker已确认消息，标识：%d，多个消息：%b", deliveryTag, multiple));
		if(multiple) {
			// headSet表示后面参数之前的所有元素，全部删除
			confirmSet.headSet(deliveryTag + lL).clear();
		} else {
			//只移除一个元素
			confirmSet.remove(deliveryTag);
			System.out.println("未确认的消息："+confirmSet);
    }
  }
});
//开启发送方确认模式
channel.confirmSelect();
for(inti=0; i<10; i++) {
	long next SeqNo=channel.get Next Publish SeqNo 0；
	//发送消息
	//String exchange，String routing Key，Basic Properties props，byte[] body
	channel.basicPublish("", QUEUE_NAME, null, (msg + "-" + i).getBytes());
	confirmSet.add(nextSeqNo);
}
System.out.println("所有消息：" + confirmSet);
  

```

Spring Boot：

Confirm模式是在Channel上开启的，Rabbit Template对Channel进行了封装。

```java
rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() {
	@Override
	public void confirm(CorrelationData correlationData, boolean ack, String cause) {
    if (!ack) {
      System.out.println("发送消息失败：" + cause);
      throw new RuntimeRxception("发送异常：" + cause);
    }
  }
}); 
```



### 1.2消息从交换机路由到队列

第二个环节就是消息从交换机路由到队列。大家来思考一下，在什么情况下，消息会无法路由到正确的队列?

可能因为routing key错误，或者队列不存在(但是生产环境基本上不会出现这两种问题)。

我们有两种方式处理无法路由的消息，一种就是让服务端重发给生产者，一种是让交换机路由到另一个备份的交换机。

1. 消息回发

   ```java
   channel.addReturnListener(new ReturnListener) {
     public void handleReturn(int replyCode,
     String reply Text,
     String exchange,
     String routing Key,
     AMQP.BasicProperties properties,
     byte[] body) throws IOException {
       System.out.println("====监听器收到了无法路由，被返回的消息===");
       System.out.println("replyText：" + replyText);
       System.out.println("exchange：" + exchange);
       System.out.println("routing Key：" + routing Key);
       System.out.println("message：" + new String(body));
     }
   });
   ```

   Spring Boot消息回发的方式：使用mandatory参数和Return Listener(在Spring AMQP中是Return Callback) 。

   ```java
   rabbitTemplate.setMandatory(true);
   
   rabbitTemplate.setReturn Callback(new RabbitTemplate.ReturnCallback() {
     public void returnedMessage(Message message,
     int replyCode,
     String replyText,
     String exchange,
     String routing Key) {
       System.out.println("回发的消息：");
       System.out.println("replyCode：" + replyCode);
       System.out.println("replyText：" + reply Text);
       System.out.println("exchange：" + exchange);
       System.out.println("routingKey：" + routingKey);
     }
   })；
   ```

   

2. 消息路由到备份交换机的方式。

   在创建交换机的时候，从属性中指定备份交换机。

   ```java
   Map<String, Object> arguments = new HashMap<String, Object>();
   arguments.put("alternate-exchange", "ALTERNATE_EXCHANGE"); //指定交换机的备份交换机
   channel.exchangeDeclare("TEST_EXCHANGE", "topic", false, false, false, arguments);
   ```

   (注意区别，队列可以指定死信交换机；交换机可以指定备份交换机)



### 1.3消息在队列存储

第三个环节是消息在队列存储，如果没有消费者的话，队列一直存在在数据库中。如果RabbitMQ的服务或者硬件发生故障，比如系统宕机、重启、关闭等等，可能会导致内存中的消息丢失，所以我们要把消息本身和元数据(队列、交换机、绑定)都保存到磁盘。

解决方案：

1. 队列持久化

   ```java
   channel.queueDeclare(QUEUE_NAME, false, false, false, null);
   ```

   durable：没有持久化的队列，保存在内存中，服务重启后队列和消息都会消失(钱和人一起没了)。

   auto Delete：没有消费者连接的时候，自动删除。

   exclusive：排他性队列的特点是：

   1. 只对首次声明它的连接(Connection) 可见
   2. 会在其连接断开的时候自动删除。

2. 交换机持久化

   ```java
   @Bean("MyExchange")
   public DirectExchange exchange() {
     //exchange Name，durable，exclusive，auto Delete，Properties
     return new DirectExchange("GP_TEST_EXCHANGE", true, false, new HashMap<>);
   }
   ```

   

3. 消息持久化

   ```java
   AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
     .deliveryMode(2) // 2代表持久化
   	.contentEncoding("UTF-8") //编码
   	.expiration("10000") //TTL，过期时间
   	.headers(headers) //自定义属性
   	.priority(5) //优先级，默认为5，配合队列的x-max-priority属性使用
   	.messageId(String.valueOf(UUID.random UUID()))
   	.build();
   ```

   如果消息没有持久化，保存在内存中，队列还在，但是消息在重启后会消失(人生最最痛苦的事情：人还在，钱没了)。

4. 集群
   如果只有一个RabbitMQ的节点，即使交换机、队列、消息做了持久化，如果服务崩溃或者硬件发生故障(机房起火被炸了我们先不讲......) ，RabbitMQ的服务一样是不可用的。

   所以为了提高MQ服务的可用性，保障消息的传输，我们需要有多个RabbitMQ的节点



### 1.4消息投递到消费者

如果消费者收到消息后没来得及处理即发生异常，或者处理过程中发生异常，会导致④失败。服务端应该以某种方式得知消费者对消息的接收情况，并决定是否重新投递这条消息给其他消费者。

RabbitMQ提供了消费者的消息确认机制(message acknowledgement) ，消费者可以自动或者手动地发送ACK给服务端。

如果没有ACK会怎么办？永远等待下去？也不会

没有收到ACK的消息，消费者断开连接后，RabbitMQ会把这条消息发送给其他消费者。如果没有其他消费者，消费者重启后会重新消费这条消息，重复执行业务逻辑(如果代码修复好了还好)。

消费者怎么给Broker应答呢?有两种方式，一种是自动ACK，一种是手动ACK。

首先是自动ACK，这个也是默认的情况。也就是我们没有在消费者处编写ACK的代码，消费者会在收到消息的时候就自动发送ACK，而不是在方法执行完毕的时候发送ACK(并不关心你有没有正常消息)。

如果想要等消息消费完毕或者方法执行完毕才发送ACK，需要先把自动ACK设置成手动ACK。把auto Ack设置成false。

```java
channel.basicConsume(QUEUE_NAME, false, consumer);
```

这个时候RabbitMQ会等待消费者显式地回复ACK后才从队列中移去消息。

```java
channel.basicAck(envelope.getDeliveryTag(), true);
```

在Spring Boot中：
application.properties

```properties
spring.rabbitmq.listener.direct.acknowledge-mode=manual
spring.rabbitmq.listener.simple.acknowledge-mode=manual
```

SimpleRabbitListenerContainer或者SimpleRabbitListenerContainerFactory

```java
factory.setAcknowledgeMode(AcknowledgeMode.MANUAL);
```

注意这三个值的区别：

- NONE：自动ACK
- MANUAL：手动ACK
- AUTO：如果方法未抛出异常，则发送ack。如果方法抛出异常，并且不是AmqpRejectAndDontRequeueException则发送nack，并且重新入队列。如果抛出异常时AmqpRejectAndDontRequeueException则发送nack不会重新入队列。

消费者又怎么调用ACK，或者说怎么获得Channel参数呢?

引入com.RabbitMQ.client.Channel

```java
public class SecondConsumer{
  @RabbitHandler
  public void process(String msgContent, Channel channel, Message message) throws IOException {
  	System.out.println("Second Queue received msg："+msgContent);
    channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
  }
}
```

如果消费出了问题，确实是不能发送ACK告诉服务端成功消费了怎么办?当然也有拒绝消息的指令，而且还可以让消息重新入队给其他消费者消费。

如果消息无法处理或者消费失败，也有两种拒绝的方式，Basic.Reject() 拒绝单条，Basic.Nack() 批量拒绝。

```java
if(msg.contains("拒收")) {
// 拒绝消息
// requeue：是否重新入队列，true：是； false：直接丢弃，相当于告诉队列可以直接删除掉
// TODO 如果只有这一个消费者，requeue为true的时候会造成消息重复消费
	channel.basicReject(envelope.getDeliveryTag(), false);
} else if(msg.contains("异常")) {
  // 批量拒绝
  // requeue：是否重新入队列
  // TODO 如果只有这一个消费者，requeue为true的时候会造成消息重复消费
  channel.basicNack(envelope.getDeliveryTag(), true, false);
}
```

如果requeue参数设置为true，可以把这条消息重新存入队列，以便发给下一个消费者(当然，只有一个消费者的时候，这种方式可能会出现无限循环重复消费的情况。可以投递到新的队列中，或者只打印异常日志)。

简单地总结一下：

从生产者到Broker、交换机到队列，队列本身，队列到消费者，我们都有相应的方法知道消费有没有正常流转，或者说当消息没有正常流转的时候采取相关措施。

思考：服务端收到了ACK或者NACK，生产者会知道吗?即使消费者没有接收到消息，或者消费时出现异常，生产者也是完全不知情的。这个是符合解耦思想的，不然你用MQ干嘛?

但是如果现在为了保证一致性，生产者必须知道消费者有没有成功消费，怎么办?

例如，我们寄出去一个快递，是怎么知道收件人有没有收到的?

因为有物流跟踪和签收反馈，所以寄件人可以知道。

但是，在没有用上电话的年代，我们寄出去一封信，是怎么知道收信人有没有收到信件?只有收到回信，才知道寄出的信被收到了。

所以，这个是生产者最终确定消费者有没有消费成功的两种方式：

1. 消费者收到消息，处理完毕后，调用生产者的API(思考：是否破坏解耦?)
2. 消费者收到消息，处理完毕后，发送一条响应消息给生产者。



### 1.5消费者回调

1. 调用生产者API

   例如：提单系统给其他系统发送了保险消息后(通知通知!发生了一笔保险)，其他系统必须在处理完消息后调用提单系统提供的API，来修改提单系统中这笔数据的状态。只要API没有被调用，数据状态没有被修改，提单系统就认为下游系统没有收到这条消息。

2. 发送响应消息给生产者

   例如：商业银行与人民银行二代支付通信(使用IBM MQ) ，无论是人行收到了商业银行的消息，还是商业银行收到了人行的消息，都必须发送一条响应消息(叫做回执报文)。

   整个通信的流程设计得非常复杂，但是对于金融场景下的消息可靠性保证，是很有用的。

   ![image-20210509162551830](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/rabbitmq/20210509162551.png)



### 1.6补偿机制

如果生产者的API就是没有被调用，也没有收到消费者的响应消息，怎么办?

不要着急，先等等，可能是消费者处理时间太长或者网络超时。

你发微信消息给朋友去吃烧烤，他没有立即回复消息，别担心，可能是路上出车祸了。但是如果一直不回复消息就不行了。

生产者与消费者之间应该约定一个超时时间，对于超出这个时间没有得到响应的消息，才确定为消费失败，比如5分钟。

5分钟，对于临时性故障的处理，比如网络恢复，或者重启应用，重启数据库，应该够了。

过了5分钟依然没有得到回复的消息，我们才判断为消费失败。

确定消费失败以后怎么办呢?肯定要重发消息了。

不过这里面有几个问题：

1. 谁来重发?

   假设这个消息是由业务人员操作产生的，对于异步的操作来说，他只要提交了请求就OK了，后面成不成功是不归他管的。所以肯定是后台的代码重发的。不可能让业务人员重新做一笔交易。

   先创建一个定时任务，比如每30秒跑一次，找到业务表里面的这条业务状态是中间状态的记录，查询出来，构建为MQ消息，重新发送。

   也可以单独设计设计一张消息表，把本系统所以发送出去的消息全部异步地登记起来，找出状态是未回复的消息发送(注意注意：这种做法毫无疑问会消耗性能、消耗数据库存储空间)。

2. 隔多久重发一次?

   假如消费者一直没有回复，比如它重启要20分钟，你5分钟之内尝试重发，肯定还不能正常消费。所以重发肯定不只发一次，要尝试多次，但是又不能发得太频繁，给它一点恢复的时间。比如可以设置为1分钟重发一次。也可以设置衰减机制，第一次隔一
   分钟，第二次隔两分钟(谈恋爱的时候，发消息不回复，开始一天联系一次，后来一周联系一次，慢慢地失去了信心)。

   时间由定时任务的执行时间决定。

3. 一共重发几次?

   好了，终极的问题来了，消费者真的是死了!你跟对方项目经理反馈了这个问题，他说暂时恢复不了，明天才能修复这个bug。而你的程序10分钟重发一次，一个小时6条消息，一天就重发了100多条消息，后面绝大部分时间都是在做无用功，还无端造成
   了服务端的MQ消息堆积。

   所以，重发消息务必要控制次数，比如设置成3次。

   这个要在消息表里面记录次数来实现，发一次就加1。

4. 重发什么内容?

   重发，是否发送一模一样的消息?

   

   参考：
   ATM机上运行的系统叫C端(ATMC) ，银行的前置系统或者渠道系统叫P端(ATMC) ，它接收AT MC的消息，再转发给卡系统或者核心系统。

   1. 如果客户存款，没有收到核心系统的应答。怎么处理?

      因为不知道有没有记账成功，不能给客户吐钞，否则会造成银行短款。因为已经吞钞了，所以要保证成功。最多发送3次存款确认报文；

   2. 如果客户取款，AT MC未得到核心系统的应答时，怎么处理?

      因为没有吐钞，所以要保证失败。最多发送3次存款冲正报文。



### 1.7消息幂等性

如果消费者状态是正常的，每一条消息都可以正常处理。只是在响应或者调用API的时候出了问题，会不会出现消息的重复处理?例如：存款1000元，ATMC重发了3次存款消息，核心系统一共处理了4次，账户余额增加了4000元。

所以，为了避免相同消息的重复处理，必须要采取一定的措施。RabbitMQ服务端是没有这种控制的(同一批的消息有个递增的Delivery Tag) ，它并不知道对于你的业务来说什么才是重复的消息。所以这个只能在消费端控制。

如何避免消息的重复消费?

消息出现重复可能会有两个原因：

1. 生产者的问题，环节①重复发送消息，比如在开启了Confirm模式但未收到
   确认，消费者重复投递。

2. 环节④出了问题，由于消费者未发送ACK或者其他原因，消息重复消费。

3. 生产者代码或者网络问题。

   对于重复发送的消息，可以对每一条消息生成一个唯一的业务ID，通过日志或者消息落库来做重复控制。

   例如：在金融系统中有一个叫流水号的东西。不管你在柜面汇款，还是ATM取款，或者信用卡消费，都会有一个唯一的序号。通过这个序号就可以找到唯一的一笔消息。

   参考：银行的重账控制环节，对于进来的每一笔交易，第一件要做的事情就是查询是否重复。

   大家有没有用微信支付的时候被提示可能是重复支付?

   业务要素一致(付款人ID、商户ID、交易类型、金额、交易地点、交易时间)，可能是同一笔消息。



### 1.8最终一致性

如果确实是消费者宕机了，或者代码出现了BUG导致无法正常消费，在我们尝试多次重发以后，消息最终也没有得到处理，怎么办?

刚刚我们说了，如果对方项目经理很屌，他说今天修复不了，那怎么办?不可能我们这边的消息一直是未回复的状态吧?

例如存款的场景，客户的钱已经被吞了，但是余额没有增加，这个时候银行出现了长款，应该怎么处理?(那还用说，到了我的机器里面不就是我的?)

如果客户没有主动通知银行，他没有及时查询余额，这个问题是怎么发现的?银行最终怎么把这个账务做平?

在我们的金融系统中，都会有双方对账或者多方对账的操作，通常是在一天的业务结束之后，第二天营业之前。金融系统里面，多一分钱少一分钱都是非常严重的问题。

我们会约定一个标准，比如ATM跟核心系统对账，肯定是以核心系统的账务为准。ATMC获取到核心的对账文件，然后解析，登记成数据，然后跟自己记录的流水比较，找出核心有ATM没有，或者ATM有核心没有，或者两边都有但是金额不一致的数据。

对账之后，我们再手工平账。比如取款记了账但是没吐钞的，做一笔冲正。存款吞了钞没记账的，要么把钱退给客户，要么补一笔账。


### 1.9消息的顺序性

消息的顺序性指的是消费者消费消息的顺序跟生产者生产消息的顺序是一致的。

例如：商户信息同步到其他系统，有三个业务操作：1、新增门店2、绑定产品3、激活门店，这种情况下消息消费顺序不能颠倒(门店不存在时无法绑定产品和激活)。

又比如：1、发表微博；2、发表评论；3、删除微博。顺序不能颠倒。

在RabbitMQ中，一个队列有多个消费者时，由于不同的消费者消费消息的速度是不一样的，顺序无法保证。只有一个队列仅有一个消费者的情况才能保证顺序消费(不同的业务消息发送到不同的专用的队列)。

除非负载的场景，不要用多个消费者消费消息。消费端捕获异常。



## 2.集群与高可用

### 2.1为什么要做集群部署

集群主要用于实现高可用与负载均衡。

高可用：如果集群中的某些MQ服务器不可用，客户端还可以连接到其他MQ服务器。不至于影响业务。

负载均衡：在高并发的场景下，单台MQ服务器能处理的消息有限，可以分发给多台MQ服务器。减少消息延迟。



### 2.2RabbitMQ如何支持集群

应用做集群，需要面对数据同步和通信的问题。因为Erlang天生具备分布式的特性，所以RabbitMQ天然支持集群，不需要通过引入ZK来实现数据同步。

RabbitMQ通过.erlang.cookie(默认路径：/var/lib/rabbitmq/) 来验证身份，需要在所有节点上保持一致。

服务的端口是5672，UI的端口是15672，集群的端口是25672。

集群通过25672端口两两通信，需要开放防火墙的端口。

需要注意的是，RabbitMQ集群无法搭建在广域网上，除非使用federation或者shovel等插件(没这个必要，在同一个机房做集群) 。



### 2.3RabbitMQ的节点类型

集群有两种节点类型，一种是磁盘节点(Disc Node) ，一种是内存节点(RAM Node) 。

磁盘节点：将元数据(包括队列名字属性、交换机的类型名字属性、绑定、vhost)放在磁盘中。未指定类型的情况下，默认为磁盘节点。

集群中至少需要一个磁盘节点用来持久化元数据，否则全部内存节点崩溃时，就无从同步元数据。

内存节点：将元数据放在内存中。

PS：内存节点会将磁盘节点的地址存放在磁盘(不然重启后就没有办法同步数据了)。如果是持久化的消息，会同时存放在内存和磁盘。

我们一般把应用连接到内存节点(读写快)，磁盘节点用来备份。

集群的配置步骤：

1. 配置hosts以便相互通信
2. 同步erlang.cookie
3. 加入集群（join cluster命令）

RabbitMQ有两种集群模式：普通集群模式和镜像集群模式。

### 2.4集群类型

#### 2.4.1普通集群

普通集群模式下，不同的节点之间只会相互同步元数据(交换机、队列、绑定关系、Vhost的定义) ，而不会同步消息。

![image-20210509164528094](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/rabbitmq/20210509164528.png)

比如，队列1的消息只存储在节点1上。节点2和节点3同步了队列1的定义，但是没有同步消息。

假如生产者连接的是节点3，要将消息通过交换机A路由到队列1，最终消息还是会转发到节点1上存储，因为队列1的内容只在节点1上。

同理，如果消费者连接是节点2，要从队列1上拉取消息，消息会从节点1转发到节点2。其他节点起到一个路由作用，类似于指针。

这样是不是会有一个问题：如果节点1挂了，队列1的所有数据就全部丢失了。为什么不直接把消息在所有节点上复制一份?

主要是出于存储和同步数据的网络开销的考虑，如果所有节点都存储相同的数据，就无法达到线性地增加性能和存储容量的目的(堆机器)。

这就是一个分片存储的思想。

当然，如果需要保证队列的高可用性，就不能用这种集群模式了，因为节点失效将导致相关队列不可用。因此我们需要第二种集群模式。

#### 2.4.2镜像集群

![image-20210509164903922](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/rabbitmq/20210509164904.png)

镜像队列模式下，消息内容会在镜像节点间同步，可用性更高。不过也有一定的副作用，系统性能会降低，节点过多的情况下同步的代价比较大。

集群模式可以通过UI或者CLI或者HTTP操作

Admin——Policies

| 操作方式             | 命令或步骤                                                   |
| -------------------- | ------------------------------------------------------------ |
| rabbitmqctl(windows) | rabbitmqctl set_policy ha-all "^ha." "{""ha-mode"":""all""}" |
| HTTP API             | PUT /api/policies/%2f/ha-all {"pattern":"^ha.", "definition":"{"ha-mode":"all"}"} |
| WebUI                | 1. avigate to admin > policies > add / update a policy<br />2. Name 输入：mirror_image<br />3. Pattern输入：mirror_image<br />4.Definition点击HAmode，右边输入：all<br />5.Add policy |



#### 2.4.3高可用

https://gper.club/articles/7e7e7f7ff3g5bgc5g6c
集群搭建成功后，如果有多个内存节点，那么生产者和消费者应该连接到哪个内存节点?如果我们在客户端代码中根据一定的策略来选择要使用的服务器，那每个地方都要修改，客户端的代码就会出现很多的重复，修改起来也比较麻烦。

所以需要一个负载均衡的组件（例如HAProxy，LVS，Nignx），由负载的组件来做路由。这个时候，只需要连接到组件的IP地址就可以了。

![image-20210509193822697](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/rabbitmq/20210509193822.png)

负载分为四层负载和七层负载。

- 四层负载：工作在OSI模型的第四层，即传输层(TCP位于第四层) ，它是根据IP端口进行转发(LVS支持四层负载) 。RabbitMQ是TCP的5672端口。
- 七层负载：工作在第七层，应用层(HTTP位于第七层) 。可以根据请求资源类型分配到后端服务器(Ng in x支持七层负载； HA Proxy支持四层和七层负载) 。

但是，如果这个负载的组件也挂了呢?客户端就无法连接到任意一台MQ的服务器了。所以负载软件本身也需要做一个集群。新的问题又来了，如果有两台负载的软件，客户端应该连哪个?

![image-20210509194207322](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/rabbitmq/20210509194207.png)

负载之上再负载?陷入死循环了。这个时候我们就要换个思路了。

我们应该需要这样一个组件：

1. 它本身有路由(负载)功能，可以监控集群中节点的状态(比如监控HA Proxy) ，如果某个节点出现异常或者发生故障，就把它剔除掉。
2. 为了提高可用性，它也可以部署多个服务，但是只有一个自动选举出来的MASTER服务器(叫做主路由器) ，通过广播心跳消息实现。
3. MASTER服务器对外提供一个虚拟IP，提供各种网络功能。也就是谁抢占到VIP，就由谁对外提供网络服务。应用端只需要连接到这一个IP就行了。

这个协议叫做VRRP协议(虚拟路由冗余协议Virtual Router Redundancy Protocol) ，这个组件就是Keepalived，它具有Load Balance和High Availability的功能。

下面我们看用HAProxy和Keepalived如何实现RabbitMQ的高可用（Mysql、Mycat、Redis类似）

**基于Docker安装HAProxy负载+Keepalived高可用**

![image-20210509195216701](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/rabbitmq/20210509195216.png)



1. 规划了两个内存节点，一个磁盘节点。所有的节点之间通过镜像队列的方式同步数据。内存节点用来给应用访问，磁盘节点用来持久化数据。

2. 为了实现对两个内存节点的负载，我们安装了两个HA Proxy，监听两个5672和15672的端口。

3. 安装两个Keepalived，一主一备。两个Keepalived抢占一个 VIP。谁抢占到这个VIP，应用就连接到谁，来执行对MQ的负载。

   这种情况下，我们的Keepalived挂了一个节点，没有影响，因为BACKUP会变成MASTER，抢占VIP。HA Proxy挂了一个节点，没有影响，我们的VIP会自动路由的可用的HA Proxy服务。RabbitMQ挂了一个节点，没有影响，
   因为HA Proxy会自动负载到可用的节点。

## 3.总结

### 3.2配置文件命名规范

1. 元数据的命名集中放在properties文件中，不要用硬编码。如果有多个系统，可以配置多个xxx_mq.properties。

2. 命名体现元数据的类型

   - 虚拟机命名：XXX_VHOST
   - 交换机命名：XXX EXCHANGE
   - 队列名命名：XXX_QUEUE

3. 命名体现数据来源和去向

4. 例如：销售系统发往产品系统的交换机：SALE_TO_PRODUCT_EXCHANGE。做到见名知义，不用去查文档(当然注释是必不可少的)

   

### 3.5生产环境运维监控

虽然RabbitMQ提供了一个简单的管理界面，但是如果对于系统性能、高可用和其他参数有一些定制化的监控需求的话，我们就需要通过其他方式来实现监控了。

生产环境可以使用zabbix+graf an a实现。

主要关注：磁盘、内存、连接数

### 3.6日志追踪

RabbitMQ可以通过Firehose功能来记录消息流入流出的情况，用于调试，排错。

它是通过创建一个TOPIC类型的交换机(am q.RabbitMQ.trace) ，把生产者发送给Broker的消息或者Broker发送给消费者的消息发到这个默认的交换机上面来实现的。

另外RabbitMQ也提供了一个Firehose的GUI版本，就是Tracing插件。

启用Tracing插件后管理界面右侧选项卡会多一个Tracing，可以添加相应的策略。

RabbitMQ还提供了其他的插件来增强功能。

https://www.rabbitmq.com/firehose.html
https://www.rabbitmq.com/plugins.html



### 3.7如何减少连接数

在发送大批量消息的情况下，创建和释放连接依然有不小的开销。我们可以跟接收方约定批量消息的格式，比如支持JSON数组的格式，通过合并消息内容，可以减少生产者/消费者与Broker的连接。

比如：活动过后，要全范围下线产品，通过Excel导入模板，通常有几万到几十万条
解绑数据，合并发送的效率更高。

建议单条消息不要超过4M(4096KB)，一次发送的消息数需要合理地控制。

