# Kafka的实现原理

## 消息中间件能做什么

> 消息中间件主要解决的就是分布式系统之间消息传递的问题，它能够屏蔽各种平台以及协议之间的特性，实现应用程序之间的协同。举个非常简单的例子，就拿一个电商平台的注册功能来简单分析下，用户注册这一个服务，不单单只是insert一条数据到数据库里面就完事了，还需要发送激活邮件、发送新人红包或者积分、发送营销短信等一系列操作。假如说这里面的每一个操作，都需要消耗1s，那么整个注册过程就需要耗时4s才能响应给用户。

![image](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/kafka/1593266220.png)

> 但是我们从注册这个服务可以看到，每一个子操作都是相对独立的，同时，基于领域划分以后，发送激活邮件、发送营销短信、赠送积分及红包都属于不同的子域。所以我们可以对这些子操作进行来实现异步化执行，类似于多线程并行处理的概念。

> 如何实现异步化呢？用多线程能实现吗？多线程当然可以实现，只是，消息的持久化、消息的重发这些条件，多线程并不能满足。所以需要借助一些开源中间件来解决。而分布式消息队列就是一个非常好的解决办法，引入分布式消息队列以后，架构图就变成这样了（下图是异步消息队列的场景）。通过引入分布式队列，就能够大大提升程序的处理效率，并且还解决了各个模块之间的耦合问题

> 这个是分布式消息队列的第一个解决场景【异步处理】

![image](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/kafka/1593266260.png)

> 我们再来展开一种场景，通过分布式消息队列来实现流量整形，比如在电商平台的秒杀场景下，流量会非常大。通过消息队列的方式可以很好的缓解高流量的问题

![image](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/kafka/1593266360.png)

用户提交过来的请求，先写入到消息队列。消息队列是有长度的，如果消息队列长度超过指定长度，直接抛弃

秒杀的具体核心处理业务，接收消息队列中消息进行处理，这里的消息处理能力取决于消费端本身的吞吐量

当然，消息中间件还有更多应用场景，比如在弱一致性事务模型中，可以采用分布式消息队列的实现最大能力通知方式来实现数据的最终一致性等等

## Java中使用kafka进行通信

### 依赖

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>2.0.0</version>
</dependency>
```

### 发送端代码

```java
import com.sendbp.eduz.kafka.Kafka4JTest;
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.IntegerSerializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Optional;
import java.util.Properties;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.TimeUnit;

/**
 * 生产者
 *
 * @author JC.Lin
 * @date 2020-06-24 16:22
 */
public class Producer extends Thread {
    private static final Logger logger = LoggerFactory.getLogger(Kafka4JTest.class);

    private final KafkaProducer<Integer, String> producer;
    private final String topic;

    public Producer(String topic) {
        Properties properties = new Properties();
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "<外网IP>:9092,<外网IP>:9095,<外网IP>:9096");
        properties.put(ProducerConfig.CLIENT_ID_CONFIG, "practice-producer");
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class.getName());
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        // batch.size: 生产者发送多个消息到broker上的同一个分区时，为了减少网络请求带来的性能开销，通过批量的方式
        //来提交消息，可以通过这个参数来控制批量提交的字节数大小，默认大小是16384byte,也就是16kb，
        //意味着当一批消息大小达到指定的batch.size的时候会统一发送
        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, "16kb");
        // linger.ms: Producer默认会把两次发送时间间隔内收集到的所有Requests进行一次聚合然后再发送，以此提高吞
        //吐量，而linger.ms就是为每次发送到broker的请求增加一些delay，以此来聚合更多的Message请求。
        //这个有点想TCP里面的Nagle算法，在TCP协议的传输中，为了减少大量小数据包的发送，采用了Nagle
        //算法，也就是基于小包的等-停协议
//        properties.put(ProducerConfig.LINGER_MS_CONFIG, "");

        producer = new KafkaProducer<>(properties);
        this.topic = topic;
    }

    @Override
    public void run() {
        int num = 0;
        while (num < 50) {
            String msg = "pratice test message:" + num;
            try {
                // 同步方式
//                producer.send(new ProducerRecord<>(topic, msg)).get();

                // 异步方式
                producer.send(new ProducerRecord<>(topic, msg), (recordMetadata, e) -> {
                    System.out.println("callback: " + recordMetadata.offset() + "->" + recordMetadata.partition());
                });

                TimeUnit.SECONDS.sleep(2);
                num++;
            } catch (Exception e) {
                logger.error("", e);
            }
        }

    }

    public static void main(String[] args) {
        new Producer("test").start();
    }

}
```

### 接收端代码

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.IntegerDeserializer;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Collections;
import java.util.Properties;

/**
 * 消费者
 * @author JC.Lin
 * @date 2020-06-24 16:23
 */
public class Consumer extends Thread {

    private final KafkaConsumer<Integer, String> consumer;
    private final String topic;

    public Consumer(String topic) {
        Properties properties = new Properties();
        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "<外网IP>:9092,<外网IP>:9095,<外网IP>:9096");
        properties.put(ConsumerConfig.GROUP_ID_CONFIG, "practice-consumer");
        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true");//设置offset自动提交
        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");//自动提交间隔时间
        properties.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, "30000");
        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class.getName());
        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");//对于当前groupid来说，消息的offset从最早的消息开始消费
        consumer = new KafkaConsumer<>(properties);
        this.topic = topic;
    }

    @Override
    public void run() {
        while (true) {
            consumer.subscribe(Collections.singleton(this.topic));
            ConsumerRecords<Integer, String> records = consumer.poll(Duration.ofSeconds(1));
            records.forEach(record -> {
                System.out.println(record.key() + " " + record.value() + " -> offset:" + record.offset());
            });
        }
    }

    public static void main(String[] args) {
        new Consumer("test").start();
    }

}
```

### batch.size

生产者发送多个消息到broker上的同一个分区时，为了减少网络请求带来的性能开销，通过批量的方式来提交消息，可以通过这个参数来控制批量提交的字节数大小，默认大小是16384byte,也就是16kb，意味着当一批消息大小达到指定的batch.size的时候会统一发送

### linger.ms

Producer默认会把两次发送时间间隔内收集到的所有Requests进行一次聚合然后再发送，以此提高吞吐量，而linger.ms就是为每次发送到broker的请求增加一些delay，以此来聚合更多的Message请求。这个有点想TCP里面的Nagle算法，在TCP协议的传输中，为了减少大量小数据包的发送，采用了Nagle算法，也就是基于小包的等-停协议。

> batch.size和linger.ms这两个参数是kafka性能优化的关键参数，会发现batch.size和linger.ms这两者的作用是一样的，如果两个都配置了，那么怎么工作的呢？实际上，当二者都配置的时候，只要满足其中一个要求，就会发送请求到broker上

### group.id

`consumer group`是kafka提供的可扩展且具有容错性的消费者机制。既然是一个组，那么组内必然可以有多个消费者或消费者实例(consumer instance)，它们共享一个公共的ID，即group ID。组内的所有消费者协调在一起来消费订阅主题(subscribed topics)的所有分区(partition)。当然，**每个分区只能由同一个消费组内的一个consumer来消费**.

如下图所示，分别有三个消费者，属于两个不同的group，那么对于firstTopic这个topic来说，这两个组的消费者都能同时消费这个topic中的消息，对于此事的架构来说，这个firstTopic就类似于ActiveMQ中的topic概念。

![image](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/kafka/1593266902.png)

不同的组的消费者可以在同一时间接收到相同的信息

如下图所示，如果3个消费者都属于同一个group，那么此事firstTopic就是一个Queue的概念

![image](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/kafka/1593266955.png)

同一个组内的消费者，同一时间下一个消息只能由一个消费者消费。

### enable.auto.commit

消费者消费消息以后自动提交，只有当消息提交以后，该消息才不会被再次接收到，还可以配合
`auto.commit.interval.ms`控制自动提交的频率。

当然，我们也可以通过`consumer.commitSync()`的方式实现手动提交。

### auto.offset.reset

这个参数是针对新的groupid中的消费者而言的，当有新groupid的消费者来消费指定的topic时，对于该参数的配置，会有不同的语义

- auto.offset.reset=latest情况下，新的消费者将会从其他消费者最后消费的offset处开始消费Topic下的
消息
- auto.offset.reset=earliest情况下，新的消费者会从该topic最早的消息开始消费
- auto.offset.reset=none情况下，新的消费者加入以后，由于之前不存在offset，则会直接抛出异常。

### max.poll.records

此设置限制每次调用poll返回的消息数，这样可以更容易的预测每次poll间隔要处理的最大值。通过调整此值，可以减少poll间隔

## Springboot+kafka

springboot的版本和kafka的版本，有一个对照表格，如果没有按照正确的版本来引入，那么会存在版本问题导致ClassNotFound的问题，具体请参考

https://spring.io/projects/spring-kafka

![image](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/kafka/1593266490.png)

### 依赖

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
    <version>2.2.0.RELEASE</version>
</dependency>
```

### 配置

springboot-kafka自动装配类：org.springframework.boot.autoconfigure.kafka.KafkaProperties

```yaml
spring: 
  kafka:
    bootstrapservers: <公网IP>:9092,<公网IP>:9095,<公网IP>:9096

    producer:
      keyserializer: org.apache.kafka.common.serialization.StringSerializer
      valueserializer: org.apache.kafka.common.serialization.StringSerializer

    consumer:
      group-id: test-consumer-group
      auto-offset-reset: earliest
      enable-auto-commit: true
      keydeserializer: org.apache.kafka.common.serialization.StringDeserializer
      valuedeserializer: org.apache.kafka.common.serialization.StringDeserializer
```


### KafkaProducer

```java
@Component
public class KafkaProducer {
    @Autowired
    private KafkaTemplate<String,String> kafkaTemplate;
    
    public void send(){
        kafkaTemplate.send("test","msgKey","msgData");
    }
}
```

### KafkaConsumer

```java
@Component
public class KafkaConsumer {
    @KafkaListener(topics = {"test"})
    public void listener(ConsumerRecord record){
        Optional<?> msg=Optional.ofNullable(record.value());
        if(msg.isPresent()){
            System.out.println(msg.get());
        }
    }
}
```

### Test

```java
import org.junit.AfterClass;
import org.junit.runner.RunWith;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.ActiveProfiles;
import org.springframework.test.context.junit4.SpringRunner;

import java.io.IOException;
import java.io.OutputStream;
import java.io.PrintStream;

@RunWith(SpringRunner.class)
@SpringBootTest(classes = KafkaApplication.class)
@ActiveProfiles("dev")
public abstract class TestBase {

    /**
     * 在所有测试运行完毕后关闭控制台输出，因为Spring Netflix内部Bug会在测试运行完毕后结束进程时产生与测试无关的异常
     */
    @AfterClass
    public static void ignoreConsolePrint(){
        OutputStream ignoreOutputStream = new OutputStream() {
            @Override
            public void write(int b) throws IOException {
                //ignore
            }
        };
        System.setOut(new PrintStream(ignoreOutputStream));
        System.setErr(new PrintStream(ignoreOutputStream));
    }

}
```

```java
import com.sendbp.eduz.TestBase;
import org.junit.Test;

import javax.annotation.Resource;

/**
 * @author JC.Lin
 * @date 2020-06-26 18:14
 */
public class SpringBootKafkaTest extends TestBase {

    @Resource
    private KafkaProducer kafkaProducer;

    @Test
    public void Test1() {
        for (int i = 0; i < 3; i++) {
            kafkaProducer.send();
            try {
                Thread.sleep(3000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

}
```

## 原理分析

从前面的整个演示过程来看，只要不是超大规模的使用kafka，那么基本上没什么大问题，否则，对于kafka本身的运维的挑战会很大，同时，针对每一个参数的调优也显得很重要。

> 据我了解，快手在使用kafka集群规模是挺大的，他们在19年的开发者大会上有提到， 总机器数大概2000 台；30 多个集群；topic 12000个；一共大概20万TP（topic partition）；每天总处理的消息数超过4万亿条；峰值超过1亿条

https://www.infoq.cn/article/Q0o*QzLQiay31MWiOBJH

### 关于Topic和Partition

#### Topic

在kafka中，topic是一个存储消息的逻辑概念，可以认为是一个消息集合。每条消息发送到kafka集群的消息都有一个类别。物理上来说，不同的topic的消息是分开存储的，

每个topic可以有多个生产者向它发送消息，也可以有多个消费者去消费其中的消息。

#### Partition(分区)

每个topic可以划分多个分区（每个Topic至少有一个分区），同一topic下的不同分区包含的消息是不同的。每个消息在被添加到分区时，都会被分配一个offset（称之为偏移量），它是消息在此分区中的唯一编号，kafka通过offset保证消息在分区内的顺序，offset的顺序不跨分区，即kafka只保证在同一个分区内的消息是有序的。

下图中，对于名字为test的topic，做了3个分区，分别是p0、p1、p2.

- 每一条消息发送到broker时，会根据partition的规则选择存储到哪一个partition。如果partition规则设置合理，那么所有的消息会均匀的分布在不同的partition中，这样就有点类似数据库的分库分表的概念，把数据做了分片处理。

![image](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/kafka/1593268195.png)


#### Topic&Partition的存储

Partition是以文件的形式存储在文件系统中，比如创建一个名为firstTopic的topic，其中有3个partition，那么在kafka的数据目录（/tmp/kafka-log）中就有3个目录，firstTopic-0~3， 命名规则是`<topic_name>-<partition_id>`

```
sh kafka-topics.sh --create --zookeeper 192.168.11.156:2181 --replication-factor 1 --partitions 3 --topic firstTopic
```