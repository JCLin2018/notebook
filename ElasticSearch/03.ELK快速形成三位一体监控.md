# ELK快速形成三位一体监控

## ES的路由机制

### 我们的ES是如何对数据进行路由的呢?

我们的ES的路由算法有一个公式:

```sh
shard_num = hash(_routing) % num_primary_shards
```

> 其中 _routing 是路由字段的值，默认使用文档的ID字段: _id 。如果我们想自己控制数据的路由规则的话，那可以修改这个默认值。修改的方式非常简单，只需要在插入数据的时候指定路由的key即可。

**举例:**

我们有3个primary shard，P0，P1，P2。每次增删改查一个document的时候，都会带过来一个 routing number，默认就是这个document的 id (可能是手动制定，也可能是自动生成) `routing = _id` 假设 id=1。会将这个routing值，传入一个hash函数中，产出一个routing值的hash值， `hash(routing) = 21`。然后将hash函数产出的值对这个index的primary shard的数量求余数，`21 % 3 = 0` 就决定了，这个document就放在P0上。

决定一个document在哪个shard上，最重要的一个值就是routing值，默认是_id，也可以手动指定，相同的routing值，每次过来，从hash函数中，产出的hash值一定是相同的

无论hash值是几，无论是什么数字，对`number_of_primary_shards`求余数，结果一定是在 `0 ~ number_of_primary_shards-1` 之间这个范围内的。0,1,2。

**为什么我们的primary shard(主分片)数量不可变**

我们来思考一下，假设我们的id为1，然后我们hash过后的值为10，这个时候我们三台服务器，我们就可以 10 % 3 得到1，也就是我们应该放在P1上，然后这个时候假设我们的分片数现在改变了，变成了4， 我存储的时候是放在P1上的，结果我现在需要进行操作，比如我想要获取我们的文档，这个时候我们计算一下分片，10%4 = 2，我们就回去P2上进行寻找，我们的P2上面必然是没有这条数据的，所以这个时候就会间接造成我们数据的丢失，或者说不可访问。所以我们的primary shard (主分片) 数量不可变，但是我们的replica shard (副本分片) 是可以随时修改的，因为我们的路由算法跟我们的副本分片没有任何关系。

### 脑裂

ES在主节点上产生分歧，产生多个主节点，从而使集群分裂，使得集群处于异常状态。这个现象叫做脑裂。

**ES脑裂可能的原因:**

- 由于网络延迟，导致我们的主节点没有响应，这个时候我们的集群是不是就会认为我们的主节点已经死亡，然后重新选主。
- 未做节点分离。 master与data为同一节点。当我们的节点既为主节点，又为数据节点的时候，这个时候我有非常多的数据，数据全部集中在我们的主节点，然后当我们的数据访问量过大的时候，是不是也可能会导致Master节点停止响应(假死状态，因为cpu资源都用来处理数据)。从而导致我们的集群重新选主
- JVM内存设置过小

**解决方案:**

- 设置超时时间，或者设计一个类似自我保护机制。
- 节点分离

> ```sh
> # 主节点配置为
> node.master: true 
> node.data: false 
> # 数据节点配置为 
> node.master: false 
> node.data: true
> ```

- 修改JVM内存，在config/jvm.options 文件里将 -Xms 和 -Xmx 修改得更大，一般建议为服务器的内存一半。

### 集群协调

**定义:**

我们的Elasticsearch集群可以执行需要多个节点协同工作的任务。

搜索必须被路由到所有正确的分片，不然我们搜索的结果可能会不太准确。在索引或删除某些文档时，我们就必须更新每个副本。每个客户端请求都必须被接收它的节点转发到能够处理它的节点。每个节点都必须了解集群的情况、现状，这样它们就可以执行搜索、索引和其他协调活动。 这个情况或者说现状就是指集群状态。也就是集群状态我们的集群的节点集，以及所有集群级别的设置，集群状态决定了索引的映射和设置、分配给每个节点的分片以及同步的分片副本。我们需要在集群中保持这些元数据的一致性。7.0推出的很多特性(包括基于序号的复制和跨集群复制)，这些特性之所以能够正确工作，主要是因为它们依赖了集群状态的一致性。

### 仲裁机制

它使用了节点仲裁机制，只有在多数节点接受集群状态更新之后，集群状态的更新才被认为是成功的，
从而实现了这种弹性。仲裁是集群中符合主节点条件的节点的一个子集。仲裁的优势在于一些节点可
能会连接失败，但不会影响集群的可用性。在选择仲裁节点时要十分小心，这样集群就不会选举出两个
独立的主节点，避免这两个主节点做出不一致的决策，最终导致数据丢失。也就是我们刚说过的脑裂

通常，我们建议集群最少需要三个符合主节点条件的节点，如果其中一个节点失败，其他两个节点仍然
可以形成仲裁。如果一个集群少于三个符合主节点条件的节点，那它就不能安全地容忍其中任何一个节
点发生故障。相反，如果一个集群有超过三个符合主节点条件的节点，那么选举和集群状态更新可能需
要更长的时间。

**故障模式**

此外，Zen Discovery 有一个非常罕见的故障模式，在 Elasticsearch 弹性状态页上是这么描述的:“重复的网络分区可能导致集群状态更新丢失”。

> **Repeated network partitions can cause cluster state updates to be lost**

地址: ttps://www.elastic.co/guide/en/elasticsearch/resiliency/current/index.html

正常的逻辑时，我在网络分区期间，大多数节点都是正常的并且都能够符合我们主节点的资格，并且能
够收到我们的更新，只有小部分的节点高延迟无法发送我们的请求。那么接下来我们就会正常提交我们
集群状态的更新(例如映射更改或分片分配)，这个时候我们的主节点可以访问集群中足够的节点以
保证我们集群的正确运行。一旦网络分区恢复正常，我们之前隔离的节点就会追上当前状态并接收以前
错过的更改。

但是，如果我们的网络分区情况出现在我们少的一方，问题就来了，比如我们的新主节点还没有选举出来的时候，这个时候我们的剩下的节点无法支撑我们主节点的选举，那么我们的集群状态更新是不是就会丢失。这个时候，我们新版本的ES就想了一个办法。

他说，如果你用我的默认配置的话，那么我就直接自动查找我同一个主机上运行的所有节点，并且快速形成集群。然后就算你进行线性扩容，那么我只要发现他了，我们的集群名一样，我就默认发现并且加入这个集群，所以ES7中，windows版本下，或者同一集群下起多个demo集群很简单，傻瓜式安装。

**cluster.initial_master_nodes**

这种全自动集群形成机制在单台主机上可以很好地运作，但在生产环境或其他分布式环境中还不够健壮。因为有可能我们无法发现其他节点的IP地址。节点可能无法及时发现彼此，可能会形成两个或多个独立的集群。从 7.0 开始，如果你想要启动一个全新的集群，并且集群在多台主机上都有节点，那么你必须指定该集群在第一次选举中应该使用的一组符合主节点条件的节点作为选举配置。这就是所谓的集 群引导，只在首次形成集群时才需要。已经加入集群的节点将选举配置存储在它们的数据文件夹中，并在重新启动后重用这些配置，而正在加入现有集群的新节点可以从集群的当前主节点接收这些信息。什么意思呢，就是你要加一个参数 `cluster.initial_master_nodes` 参数设置一系列符合主节点条件的节点的主机名或 IP 地址来引导启动集群。你还需要配置发现子系统，这样节点就知道如何找到彼此。这也就是我们新加入的 `cluster.initial_master_nodes` 参数的含义

### 升级措施

你可以通过滚动升级或完全重新启动集群将 Elasticsearch 集群从版本 6 升级到版本 7。我们建议进行滚动升级，因为这样可以保持集群的可用性。在滚动升级到版本 7 之前，必须将版本 6 升级到版本 6.7。同时，我们的6.7版本的ES比7的节点更容易成为我们的主节点。

## 日志监控的快速搭建

> 场景1
>
> 有位同学做了一个单机项目，随着业务的增加，以及项目架构的演变以及分布式相关技术的演变，我发
> 现我们的项目越来越倾向于低限度的集中式管理，包括每个服务划分的越来越精细。在微服务架构下，
> 分布式系统变得日趋复杂，越来越多的组件开始走向分布式化，如微服务、分布式数据库、分布式缓存
> 等，使得后台服务构成了一种复杂的分布式网络，这样一个场景下，对于用户的每一次请求调用，后端
> 执行了多少组件间的调用无法知晓，由于分布式的调用，增加了程序调用异常的错误率，在这样的应用
> 场景下，新的架构技术给我们问题排查上带来了难题。

传统的项目发生问题时，比如系统异常或者系统性能出现问题时，通常都是从系统记录的日志文件中找
出蛛丝马脚，

> 比如我们可能会用 `awk sed grep` 等命令去过滤我们的日志.在执行一些复杂需求的时候,可能你需要对这些命令相当熟悉.

而对于微服务架构下的分布式部署，日志文件的分散，想从日志中查找问题工作量很大。对于用户某一
次请求调用后端哪些服务，每个服务执行情况，想从日志中获得更是不可能的事，如果没有一种办法来
解决日志问题是一件很痛苦的事情。

那么我们今天就拿我们 nginx 的日志来进行一个举例:

Nginx是一款非常优秀的web服务器，而nginx服务一般会做为我们项目的访问入口。那么，这么重要的角色我们必定需要对他的性能有一定的保障措施。如果nginx的运行出现了问题就会对项目有较大的影响，所以，我们需要对nginx的运行有监控措施，实时掌握nginx的运行情况，那就需要收集nginx的运行指标和分析nginx的运行日志了。

### 部署nginx

那么首先我们来部署一个nginx

ngixn下载地址: http://nginx.org/en/download.html

```sh
#解压文件夹，前面的下载步骤就不写进去了
tar -zxvf nginx-1.18.0.tar.gz
#安装make
yum -y install gcc automake autoconf libtool make #安装g++
yum install gcc gcc-c++
#安装pcre是为了重写rewrite，安装zlib是为了gzip压缩
yum -y install pcre-devel zlib-devel
#使用configure 跟make install就可以得到编译好的nginx程序，减轻跨平台的负担。
./configure
#同上
make install
#编译好的程序默认会在/usr/local/nginx下面
cd /usr/local/nginx/
#启动
./sbin/nginx
#通过浏览器访问页面并且查看日志 ，如果访问不到，请定位自己的错误，因为一般情况下都是因为防火墙的 问题，请参考我们的笔记2
#访问地址:
http://192.168.40.133/
#查看300行日志 习惯300行，没有特殊含义，carl的习惯
tail -300f /usr/local/nginx/logs/access.log
```

### Beats到底是什么呢?

官网: https://www.elastic.co/cn/beats/

Beats是轻量级(资源高效，无依赖性，小型)和开放源代码日志发送程序的集合，这些日志发送程序充当安装在基础结构中不同服务器上的代理，用于收集日志或指标(metrics)。这些可以是日志文件 (Filebeat)，网络数据(Packetbeat)，服务器指标(Metricbeat)等。

libbeat的地址: https://github.com/elastic/beats/tree/master/libbeat   

#### Filebeat

顾名思义，Filebeat用于收集和传送日志文件，它也是最常用的Beat。 Filebeat如此高效的事实之一就是它处理背压(后端的压力)的方式，因此，如果Logstash繁忙，Filebeat会减慢其读取速率，并在减速结束后加快节奏。 Filebeat几乎可以安装在任何操作系统上，包括作为Docker容器安装，还随附用于特定平台(例如 Apache，MySQL，Docker等)的内部模块，其中包含这些平台的默认配置和Kibana对象。

#### Packetbeat

网络数据包分析器Packetbeat是第一个引入的beat。 Packetbeat捕获服务器之间的网络流量，因此可用于应用程序和性能监视。 Packetbeat可以安装在受监视的服务器上，也可以安装在其专用服务器上。 Packetbeat跟踪网络流量，解码协议并记录每笔交易的数据。 Packetbeat支持的协议包括:DNS，HTTP，ICMP，Redis， MySQL，MongoDB，Cassandra等。

#### Metricbeat

Metricbeat是一种非常受欢迎的beat，它收集并报告各种系统和平台的各种系统级度量。 Metricbeat 还支持用于从特定平台收集统计信息的内部模块。您可以使用这些模块和称为指标集的metricsets来配置Metricbeat收集指标的频率以及要收集哪些特定指标。

#### Heartbeat

Heartbeat是用于“uptime monitoring”的。本质上，Heartbeat是探测服务以检查它们是否可访问的功能，例如，它可以用来验证服务的正常运行时间是否符合您的SLA。 您要做的就是为Heartbeat提供URL和正常运行时间指标的列表，以直接发送到Elasticsearch或Logstash以便在建立索引之前发送到您的堆栈。

#### Auditbeat

Auditbeat可用于审核Linux服务器上的用户和进程活动。与其他传统的系统审核工具(systemd， auditd)类似，Auditbeat可用于识别安全漏洞-文件更改，配置更改，恶意行为等。

#### Winlogbeat

Winlogbeat仅会引起Windows系统管理员或工程师的兴趣，因为它是专门为收集Windows事件日志而设计的组件。 它可用于分析安全事件，已安装的更新等。

#### Functionbeat

Functionbeat被定义为“serverless”的发件人，可以将其部署为收集数据并将其发送到ELK堆栈的功能。 Functionbeat专为监视云环境而设计，目前已针对Amazon设置量身定制，可以部署为Amazon Lambda函数，以从Amazon CloudWatch，Kinesis和SQS收集数据。

### FileBeat 工作原理

这里我们发现了两个重点: `prospectors` 和 `harvesters`。 这两个组件一起工作来尾随文件并将事件数据发送到您指定的输出。由于他是go语言编写，我们简单知道原理即可，有兴趣的可以去撸源码，但是 大部分同学不用理解太深。

#### 什么是harvesters

采集器 harvester 的主要职责是读取单个文件的内容。读取每个文件，并将内容发送到 the output。也就是我们的输出。 每个文件启动一个 harvester，harvester 负责打开和关闭文件，这意味着在运行时文件描述符保持打开状态。如果文件在读取时被删除或重命名，Filebeat 将继续读取文件。这有副作用，在 harvesters 关闭之前，磁盘上的空间被保留。 默认情况下，Filebeat保持文件打开，直到达到 `close_inactive` 的设置(close_inactive默认为5分钟，即5分钟之内，没有最新的日志信息产生则关闭文件句柄)。

关闭harvester有以下情况:

- 如果在harvester还在读取文件时文件被删除，那么文件处理程序关闭，释放基础资源。 
- 只有在scan_frequency过后，文件的采集才会重新开始。(scan_frequency参数默认为10秒，每隔10秒 `prospector` 检查目录中日志文件的变化情况) 
- 如果在harvester关闭的情况下移动或移除文件，则不会继续收集文件。

#### 什么是 prospector (Input)

https://www.elastic.co/guide/en/beats/libbeat/7.9/release-notes-6.3.0.html

仅仅只是改了个名字，并且将我们的配置变得简单了，但是他们做的事情并没有改变。

探测器 prospector 的主要职责是管理 harvester 并找到所有要读取的文件来源。如果输入类型为日志，则查找器将查找路径匹配的所有文件，并为每个文件启动一个 harvester。每个 prospector 都在自己的 Go 协程中运行。

> 注: Filebeat prospector只能读取本地文件，没有功能可以连接到远程主机来读取存储的文件或日志。

#### Filebeat如何保持文件状态

Filebeat保存每个文件的状态，并经常刷新状态到磁盘上的注册文件(registry)。状态用于记住 harvester 读取的最后一个偏移量，并确保所有日志行被发送(到输出)。如果输出，比如 Elasticsearch 或者 Logstash等，无法访问，那么Filebeat会跟踪已经发送的最后一行，并只要输出再次变得可用时继续读取文件。当Filebeat运行时，会将每个文件的状态保存在内存中。当Filebeat重新启动时，将使用注册文件中的数据重新构建状态，Filebeat将在最后一个已知位置继续每个 harvester。

对于每个输入，Filebeat保存它找到的每个文件的状态。因为文件可以重命名或移动，所以文件名和路径不足以标识文件。对于每个文件，Filebeat存储惟一标识符，以检测文件是否以前读取过。

如果你的情况涉及每天创建大量的新文件，你可能会发现注册表文件变得太大了。

(画外音: Filebeat保存每个文件的状态，并将状态保存到 registry_file 中的磁盘。当重新启动 Filebeat 时，文件状态用于在以前的位置继续读取文件。如果每天生成大量新文件，注册表文件可能会变得太大。为了减小注册表文件的大小，有两个配置选项可用: clean_remove 和 clean_inactive。对于你不再访问且被忽略的旧文件，建议您使用 clean_inactive。如果想从磁盘上删除旧文件，那么使用 clean_remove 选项)

#### Filebeat如何确保至少投递一次(at-least-once)?

Filebeat保证事件将被投递到配置的输出中至少一次，并且不会丢失数据。Filebeat能够实现这种行为，因为它将每个事件的投递状态存储在注册表文件中。

在定义的输出被阻塞且没有确认所有事件的情况下，Filebeat将继续尝试发送事件，直到输出确认收到事件为止。

如果Filebeat在发送事件的过程中关闭了，则在关闭之前它不会等待输出确认所有事件。当Filebeat重新启动时，发送到输出(但在Filebeat关闭前未确认)的任何事件将再次发送。这确保每个事件至少被发送一次，但是你最终可能会将重复的事件发送到输出。你可以通过设置shutdown_timeout选项，将Filebeat配置为在关闭之前等待特定的时间。

### 部署fileBeat

```sh
# 创建一个属于我们Beats的文件夹
mkdir beats 
# 将filebeat-7.9.1-linux-x86_64.tar.gz上传Beats文件夹并解压 
tar -zxvf filebeat-7.9.1-linux-x86_64.tar.gz
```

修改配置文件

```sh
# 进入我们的config文件夹
cd filebeat-7.9.1-linux-x86_64.tar.gz/config
# 创建一个yml文件
mkdir gp.yml
# 文件内容============================
# ============== Filebeat prospectors ===========
filebeat.inputs: # 6.3以前是 filebeat.prospectors:
- type: stdin # input类型,默认为log，6.0以前配置是 - input_type: log 
# 一个配置文件里面可以同时收集多个日志，也就是我们可以配置多个 - type: log，这里我们使用的是标准输入，做个演示
	enabled: true # 启用这个输入yml
output.console: # 输出到控制台，在这里我们可以指定我们的输出源，比如我们的 ElasticSearch 或者我们的 logstash
  pretty: true
  enable: true
  
# -e标准启动 -c指定配置文件 
./filebeat -e -c gp.yml
```

比如这个时候我们在界面上输入hello，这个时候我们可以看到我返回的信息。message，还有我们的版本号以及一些其他信息。

那么现在我们继续往下，我们现在有一个nginx的日志需要读取 ，那么我们应该如何读取并输出到ES呢?

这个时候我们就可以去修改一下配置文件

```sh
# gp.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /usr/local/nginx/logs/*.log
    	tags: ["nginx"]
setup.template.settings: 
	index.number_of_shards: 3 # 指定索引的分区数
output.elasticsearch: # 指定ES的配置,可以配置集群，我上课的时候直接就配置单机版了。 
	hosts: ["192.168.1.7:9200","192.168.1.7:9201","192.168.1.7:9202"]
```

这个时候，启动我们的ES，kibana随后我们直接在我们的看板上进行索引创建

```sh
fileBeat-7.9.1*
```

同时我们需要选择类型**@timestamp**，因为一般日志类型的数据都是按照时间戳来进行查询的。

OK，现在我们发现了一些问题，我们的nginx的日志数据默认都是在我们的message里面的，但是这里面的数据格式非常的难看。内容并没有经过处理，只是读取到原数据，那么对于我们后期的查看以及数据分析是非常不利的，那么我们有什么解决方案呢?

其实我们FileBeat中有大量的 module，也就是我们已经配置好的模块，我们只需要直接去启用我们的模块，就可以简化我们的配置，并且可以直接获取到我们解析好的结构化数据。

比如我们可以使用我们的命令

```sh
./filebeat modules list
```

就可以直接查看到我们非常多的一些数据，并且这些数据非常的全面，包括了nginx，ES，kafka， kibana，mongoDB,以及redis，但是我们发现，这些数据现在都是在我们的Disable里面，那么我们该如何进行启用呢?

其实，我们可以直接使用命令:

```sh
./filebeat modules enable nginx #启动 
./filebeat modules disable nginx #禁用
```

启用完成后，我们可以使用 `./filebeat modules list` 进行查看，这个时候我们就会发现，我们的 nginx 已经处于 enable 状态了。

同时，我们需要对我们module.d进行配置

```sh
cd modules.d/
vi nginx.yml # 请注意，nginx.yml的状态为disable的话，这个文件名为nginx.yml.disable
```

**nginx module的配置文件**

```sh
- module: nginx
# Access logs
	access:
		enabled: true
    var.paths: ["/usr/local/nginx/logs/access.log*"] 
  error:
  	enabled: true
  	var.paths: ["/usr/local/nginx/logs/error.log*"]
```

接下来，我们还需要配置我们的`fileBeat`的yml文件。这次我们直接用默认的文件就好了。这个时候我们还需要修改配置文件

```sh
# 在我们自定义的配置文件中加入，因为我们启用了module，所以就不需要使用inputs了。 
filebeat.inputs:
#	- type: log
# enabled: true # paths:
# - /usr/local/nginx/logs/*.log
# tags: ["nginx"]
setup.template.settings:
	index.number_of_shards: 3
output.elasticsearch:
	hosts: ["192.168.8.53:9200"]
filebeat.config.modules:
	path: ${path.config}/modules.d/*.yml
	reload.enabled: false
```

那么我们的配置需要哪些呢?

```sh
./filebeat -e -c gp.yml #filebeat版本低的话启动可能会出错， 如下:
    ERROR fileset/factory.go:142 Error loading pipeline: Error loading pipeline
for fileset nginx/access: This module requires the following     Elasticsearch
plugins: ingest-user-agent, ingest-geoip. You can install them by running the
following
    commands on all the Elasticsearch nodes:
        sudo bin/elasticsearch-plugin install ingest-user-agent
        sudo bin/elasticsearch-plugin install ingest-geoip
# 解决:需要在Elasticsearch中安装ingest-user-agent、ingest-geoip插件,命令就是上面的,注意，切换root用户
        sudo bin/elasticsearch-plugin install ingest-user-agent
				sudo bin/elasticsearch-plugin install ingest-geoip 
        # 请注意，是在ES里面的命令。导入有点慢
```

其他Module的用法参考

官方文档：https://www.elastic.co/guide/en/beats/fifilebeat/current/fifilebeat-modules.html

## Logstash背景

官方文档：https://www.elastic.co/guide/en/logstash/current/index.html

官方介绍:Logstash is an open source data collection engine with real-time pipelining capabilities。简单来说logstash就是一根具备实时数据传输能力的管道，负责将数据信息从管道的输入端传输到管道的输出端;与此同时这根管道还可以让你根据自己的需求在中间加上滤网，Logstash提供里很多功能强大的滤网以满足你的各种应用场景。Logstash常用于日志关系系统中做日志采集设备;

![](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/Elasticsearch/20201221215800.png)

**日志和指标**

- 处理所有类型的日志数据
  - 轻松获取大量Web日志(如Apche)和应用程序日志(如log4j)
  - 捕获许多其他日志格式，例如syslog，网络和防火墙日志等 
- 通过FileBeat享受补充的安全日志转发功能
- 通过TCP和UDP从Ganglia，collectd，NewFlow，JMX以及许多其他基础结构和应用程序平台收集度量

**网络**

- 将HTTP请求转换为事件
  - 从Twitter之类的网络服务中消费，以进行社会情感分析 
  - Webhook对GitHub，HipChat，JIRA和无数其他应用程序的支持 
  - 启用许多Watcher警报用例
- 通过按需轮询HTTP端点来创建事件
- 从Web应用程序界面通用捕获运行状况，性能，指标和其他类型的数据 
- 非常适合优先选择轮询控制而不是接收的方案

**数据存储和流**

从您已经拥有的数据中发现更多价值。 

- 使用JDBC接口可以更好地了解来自任何关系数据库或NoSQL存储的数据
- 统一来自Apache Kafka， RabbitMQ之类的消息传递队列中的各种数据流

**Logstash系统结构以及工作原理**

![](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/Elasticsearch/20201221220045.png)

Logstash的事件(logstash将数据流中等每一条数据称之为一个event(事件))处理流水线有三个主要角色完成:inputs –> filters –> outputs:也就是 输入→过滤器→输出。输入会生成事件，过滤器会对其进行修改，输出会将它们发送到其他地方。输入和输出支持编解码器，使您可以在数据进入或退出管道时对其进行编码或解码，而不必使用单独的过滤器。

- **inputs**: 必须，负责产生事件(Inputs generate events) 常用的输入源:

  - **file**: 从文件系统上的文件读取，就像UNIX命令一样 `tail -0F`
  - **syslog**: 在已知端口514上监听syslog消息，并根据RFC3164格式进行解析
  - **redis**: 使用redis通道和redis列表从redis服务器读取。Redis经常在集中式Logstash安装中用作“代理”，该安装会将来自远程Logstash“托运人”的Logstash事件排队
  - **Beats**: 用来做进程的事件发送

- **filters:** 可选，负责数据处理与转换(filters modify them)

  **常用的过滤器:**

  - **grok**: 解析和构造任意文本。当前，Grok是Logstash中将非结构化日志数据解析为结构化和可查询内容的最佳方法。Logstash内置了120种模式，很可能会找到满足您需求的模式
  - **mutate**: 对事件字段执行常规转换。您可以重命名，删除，替换和修改事件中的字段
  - **drop**: 完全删除事件
  - **clone**: 复制事件，可能会添加或删除字段
  - **geoip**: 添加有关IP地址地理位置的信息(还在Kibana中显示惊人的图表!)

- **outpus:** 必须，负责数据输出(outputs ship them elsewhere)

  **常用的输出: **

  - **elasticsearch**: 将事件数据发送到Elasticsearch。如果您打算以一种高效，便捷且易于查询的格式保存数据，那么Elasticsearch是您的最佳选择

  - **file**: 将事件数据写入磁盘上的文件

  - **石墨(graphite):** 将事件数据发送到石墨，石墨是一种流行的开源工具，用于存储和图形化指标

    graphite官网: http://graphite.readthedocs.io/en/latest/

  - **statsd**: 将事件数据发送到statsd，该服务“通过UDP侦听统计信息(如计数器和计时器)，并将聚合发送到一个或多个可插拔后端服务”

    其中inputs和outputs支持codecs(coder&decoder)。

- **codecs(编解码器):** 

  编解码器基本上是流过滤器，可以作为输入或输出的一部分进行操作。编解码器使您可以轻松地将消息的传输与序列化过程分开。流行的编解码器包括json，msgpack和plain (文本)。 

  - **json**: 以JSON格式编码或解码数据。
  - **multiline**: 将多行文本事件(例如java异常和stacktrace消息)合并到单个事件中。

在1.3.0 版之前，logstash 只支持纯文本形式输入，然后以过滤器处理它。但现在，我们可以在输入期处理不同类型的数据，所以完整的数据流程应该是:input | decode | filter | encode | output; codec 的引入，使得 logstash 可以更好更方便的与其他有自定义数据格式的运维产品共存，比如:graphite、fluent、netflow、collectd，以及使用 msgpack、json、edn 等通用数据格式的其他产品等 

### 部署logstash

```sh
# 检查jdk环境，要求jdk1.8+ java -version #解压安装包
tar -xvf logstash-6.5.4.tar.gz #第一个logstash示例
bin/logstash -e 'input { stdin { } } output { stdout {} }'
```

### Logstash与FileBeat的对比

很多人在使用Logstash和FileBeat的时候都会有一个疑问:

我获取日志可以直接使用FileBeat,为什么还要使用Logstash呢?EFK架构好像也能干同样的事情啊。

这里我来给大家将一个故事:

首先，我们知道 ，logstash在jvm里运行的，资源消耗比较大，所以后来作者又用golang写了一个功能较少但是资源消耗也小的轻量级的logstash-forwarder。 不过作者只是一个人，加入elastic公司以后，因为es公司本身还收购了另一个开源项目 packetbeat，而这个项目专门就是用golang的，有整个团队，所以es公司干脆把logstash- forwarder的开发工作也合并到同一个golang团队来搞，于是新的项目就叫filebeat了。但是他们在开发FileBeat的时候，并没有将Logstash的过滤功能给加进去。所以一般来说，一般结构都是 filebeat采集日志，然后发送到消息队列，redis，kafaka。然后logstash去获取，利用filter功能过滤分析，然后存储到elasticsearch中。也就是我们的第四种架构。

他们之间相当于垃圾车和环卫工人的关系。垃圾车也能直接让你把垃圾扔车上带走，但他动静大，环卫工人动静小，不吵到你，甚至在某些城市，比如上海的环卫工人还能把进行个垃圾分类。

如果一般就是to B 或者to G 的场景的话，用EFK架构也可以。这里只能说明一个问题，当你的公司日志类型太简单的情况下，没有必要使用复杂架构来增加你们公司的负担。

## ELFK一站式集成

**梳理流程**

1. 模拟应用APP生产日志，用来记录用户的操作。(生产日志切分更复杂，这里只做模拟) 
2. 通过Filebeat读取日志文件中的内容，并且将内容发送给Logstash，原因是需要对内容做处理 
3. Logstash接收到内容后，进行处理，如分割操作，然后将内容发送到Elasticsearch中 
4. Kibana会读取Elasticsearch中的数据，并且在Kibana中进行设计饼状图，最后进行展示

**伪造APP数据代码**

```java
package com.carl.demo;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import java.util.Date;
import java.util.Random;

/**
* @Date: 2020/10/21 0021 10:40
*/
@SpringBootApplication
public class OrderDistributionDemo {
    private static final Logger LOGGER = LoggerFactory.getLogger(OrderDistributionDemo.class);
		public static final String[] VISIT = new String[]{"浏览页面", "评论商品", "加入 收藏", "加入购物车", "提交订单", "使用优惠券", "领取优惠券", "搜索", "查看订单"};
  
    public static void main(String[] args) throws Exception {
        while (true) {
          Random random = new Random();
          Thread.sleep(1000);
          Long maxUserId = 9999L;
          String userId = "mi"+ random.nextLong();
          String visit = VISIT[random.nextInt(VISIT.length)];
          Date date = new Date();
          String result = "userID|" + userId + "|" + visit + "|" + date;
          LOGGER.info(result);
        } 
    }
}
```

**配置FileBeat**

```sh
# vim gp.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
  - /jar/*.log
setup.template.settings:
  index.number_of_shards: 3
output.logstash:
  hosts: ["192.168.88.22:5044"]
# 启动  fileBeat ./filebeat -e -c gp.yml
```

**配置logstash**

```sh
# vi gp.conf配置文件
input {
  beats {
    port => "5044"
  } 
}
filter {
  mutate {
    split => {"message"=>"|"}
  }
  mutate {
    add_field => {
      "userId" => "%{message[1]}"
      "visit" => "%{message[2]}"
      "date" => "%{message[3]}"
    } 
  }
  mutate {
    convert => {
      "userId" => "string"
      "visit" => "string"
      "date" => "string"
    } 
  }
} 
output {
    elasticsearch {
        hosts => [ "192.168.88.49:9200"]
    } 
}
#启动
./bin/logstash -f gp.conf
```

随后启动我们的ES与kibana，，我们创建索引，就可以看见我们的结构化数据了。

**设计饼图**

![](https://notebook1.oss-cn-shenzhen.aliyuncs.com/img/Elasticsearch/20201221220854.png)











